# Regresion Logisitica

con esta tarea vamos a comprender e implementar la Regresi√≥n Log√≠stica desde cero para la clasificaci√≥n binaria, entendiendo sus componentes matem√°ticos (funci√≥n sigmoide, hip√≥tesis, funci√≥n de coste de entrop√≠a cruzada), c√≥mo optimizarla con Descenso de Gradiente, y ser capaz de aplicarla y analizarla en un dataset.

# üìò Regresi√≥n Log√≠stica ‚Äì Conceptos Clave

## üîß Funciones a Implementar desde Cero
1. Funci√≥n Sigmoide g(z)
2. Funci√≥n de Hip√≥tesis h(X, Œ∏) (utiliza la sigmoide)
3. Funci√≥n de Coste J(X, y, Œ∏) (Entrop√≠a Cruzada Binaria)
4. Descenso de Gradiente (adaptado para clasificaci√≥n)
5. Funci√≥n de Predicci√≥n (aplica umbral 0.5 para clasificar en 0 o 1)

## üîÅ Funci√≥n Sigmoide

```math
g(z) = \frac{1}{1 + e^{-z}}
```

* Convierte cualquier n√∫mero (positivo o negativo) en un valor entre **0 y 1**.
* Tiene forma de **S**, y sus salidas son utiles por que pueden interpretarse como **probabilidades**.
* Por ejemplo, `g(0) = 0.5`, y si `z` es muy grande, `g(z)` se acerca a 1; si es muy peque√±o, se acerca a 0. 


---

## üß† Funci√≥n de Activaci√≥n Sigmoide en Regresi√≥n Log√≠stica

En la regresi√≥n log√≠stica, utilizamos la funci√≥n sigmoide como funci√≥n de activaci√≥n para modelar probabilidades. Este proceso se puede describir en los siguientes pasos:

1. **Calcular la Entrada `z`**

   Se calcula como el producto escalar entre los par√°metros y las caracter√≠sticas:

   $$
   z = \theta^T x
   $$

   > Este valor puede ser cualquier n√∫mero real: positivo, negativo o cero.

2. **Aplicar la Funci√≥n Sigmoide**

   La funci√≥n sigmoide toma `z` como entrada y devuelve un valor entre 0 y 1:

   $$
   g(z) = \frac{1}{1 + e^{-z}}
   $$

3. **Interpretar la Salida como Probabilidad**

   La salida de la funci√≥n sigmoide se interpreta como la **probabilidad estimada** de que la observaci√≥n pertenezca a la clase positiva (clase 1):

   $$
   h_\theta(x) = g(\theta^T x) \approx P(y = 1 \mid x; \theta)
   $$

---


## üß† Hip√≥tesis del Modelo

```math
h_\theta(x) = g(\theta^T x)
```

* Esta f√≥rmula se encarga de **hacer predicciones**.
* Multiplicamos los datos de entrada por los par√°metros (`Œ∏`) y aplicamos la funci√≥n sigmoide.
* El resultado es una **probabilidad** de que la salida sea `1`.
  Ejemplo: si `hŒ∏(x) = 0.8`, el modelo predice un **80% de probabilidad** de que `y = 1`.

---

## üí∞ Funci√≥n de Coste (Binary Cross-Entropy)

```math
J(\theta) = -\frac{1}{m} \sum_{i=1}^m \left[ y^{(i)} \log(h_\theta(x^{(i)})) + (1 - y^{(i)}) \log(1 - h_\theta(x^{(i)})) \right]
```

* Nos dice **qu√© tan mal est√° funcionando el modelo**.
* Penaliza m√°s fuerte cuando el modelo est√° seguro y se equivoca.
* Evitamos usar el **Error Cuadr√°tico Medio (MSE)**, porque no se adapta bien a clasificaci√≥n.

---

## üìâ Descenso de Gradiente

* Es el m√©todo que usamos para **encontrar los mejores par√°metros** (`Œ∏`).
* Calcula **qu√© tan lejos estamos** del m√≠nimo de la funci√≥n de coste.
* Da pasos peque√±os en la direcci√≥n correcta para **mejorar el modelo**.
* Aunque usamos la sigmoide, la f√≥rmula del gradiente se mantiene **muy parecida** a la de regresi√≥n lineal, lo cual simplifica la implementaci√≥n.

---

## üß≠ L√≠mite de Decisi√≥n

* Es la **frontera que separa las dos clases** (por ejemplo, spam vs no spam).
* Si `hŒ∏(x) ‚â• 0.5`, clasificamos como **1**; si es menor, como **0**.
* En un espacio 2D, es una **l√≠nea recta**; en espacios con m√°s dimensiones, es un **hiperplano**.

---

## ‚öôÔ∏è Consideraciones Pr√°cticas

* üîß **Umbral ajustable**: El valor de 0.5 puede cambiarse seg√∫n el problema (por ejemplo, para priorizar sensibilidad en medicina).
* üßØ **Regularizaci√≥n**: Podemos a√±adir t√©rminos (L1 o L2) a la funci√≥n de coste para **evitar el sobreajuste** (*overfitting*).
* üéØ **Clasificaci√≥n multiclase**: Se puede extender usando **Softmax** o estrategias **One-vs-Rest**.





### Comparaci√≥n con Otros M√©todos

| Caracter√≠stica              | Regresi√≥n Log√≠stica          | LDA / QDA                                                         |
| --------------------------- | ---------------------------- | ----------------------------------------------------------------- |
| Supuestos sobre los datos   | No hace suposiciones fuertes | Asume que los datos tienen forma de campana (distribuci√≥n normal) |
| Frontera de decisi√≥n        | Recta (lineal)               | Recta o curva (cuadr√°tica)                                        |
| C√≥mo calcula probabilidades | Directamente con la sigmoide | Basado en f√≥rmulas estad√≠sticas m√°s complejas                     |
 
## Pasos a seguir en la interacion de GD: 



### üîÑ Ciclo del Descenso de Gradiente

En cada iteraci√≥n del algoritmo de optimizaci√≥n se repiten los siguientes pasos:

1. **Calcular la Hip√≥tesis**
   Se calcula $z = X\theta$ (o $\theta^T X$ si $X$ es una sola muestra), y luego se aplica la funci√≥n sigmoide:

   $$
   h_\theta(X) = g(z)
   $$

   Esto nos da las probabilidades estimadas para cada muestra.

2. **Calcular el Error**
   Se obtiene la diferencia entre las predicciones y los valores reales:

   $$
   \text{errores} = h_\theta(X) - y
   $$

3. **Calcular el Gradiente**
   Se calcula usando la f√≥rmula vectorizada:

   $$
   \nabla J(\theta) = \frac{1}{m} X^T \cdot \text{errores}
   $$

4. **Actualizar los Par√°metros $\theta$**
   Se ajustan los par√°metros para minimizar la funci√≥n de coste:

   $$
   \theta := \theta - \alpha \cdot \nabla J(\theta)
   $$



# üìò Pasos del Algoritmo de Regresi√≥n Log√≠stica (`load_breast_cancer`)


## üî¢ Funci√≥n sigmoide

Para empezar, definimos la **funci√≥n sigmoide**, que convierte cualquier n√∫mero en un valor entre 0 y 1. Esto es muy √∫til para interpretar resultados como **probabilidades**.

Hice una lista de valores $z$ y apliqu√© la sigmoide para ver los resultados. Algunos puntos clave que me tengo que acordar:

* Si $z = 0$, la sigmoide da $0.5$.
* Si $z$ es muy grande, se acerca a $1.0$.
* Si $z$ es muy negativo, se acerca a $0.0$.

F√≥rmula:

$$
g(z) = \frac{1}{1 + e^{-z}}
$$

---

## üìà Funci√≥n de hip√≥tesis $h_\theta(x)$

Ya hab√≠amos visto esta funci√≥n antes, pero ahora la usamos junto con la sigmoide para obtener una **matriz de probabilidades**.

La f√≥rmula general es:

$$
h_\theta(x) = g(\theta^T x)
$$

---

## üí∞ Funci√≥n de coste (entrop√≠a cruzada binaria)

Para medir qu√© tan bien est√° aprendiendo el modelo, usamos la **entrop√≠a cruzada**, que castiga m√°s cuando el modelo se equivoca con confianza.

$$
J(\theta) = -\frac{1}{m} \sum \left[ y \log(h_\theta(x)) + (1 - y) \log(1 - h_\theta(x)) \right]
$$

Agregamos un peque√±o valor $\varepsilon$ para evitar errores como dividir entre cero o calcular $\log(0)$. Ese valor es tan peque√±o que no afecta el resultado final, pero ayuda a evitar problemas num√©ricos.

---

## üìâ Descenso de Gradiente (GD)

Esta funci√≥n sirve para ajustar los par√°metros $\theta$ y minimizar el error.

Primero calculamos el **gradiente**:

$$
\nabla J(\theta) = \frac{1}{m} X^T (h_\theta(X) - y)
$$

Y luego actualizamos los par√°metros con:

$$
\theta := \theta - \alpha \cdot \nabla J(\theta)
$$

Prob√© con varios valores de $\alpha$ (la tasa de aprendizaje) y vi cu√°l hac√≠a que la curva de p√©rdida bajara m√°s r√°pido y luego se estabilizara. Ese fue el mejor.

---

## üöÄ Empieza el entrenamiento

Cargu√© los datos desde `sklearn.datasets.load_breast_cancer` y segu√≠ estos pasos:

* Escal√© todas las caracter√≠sticas para que el modelo aprenda mejor.
* Agregu√© una columna de unos al dataset para que el modelo aprenda tambi√©n el **intercepto** $\theta_0$, lo que le da m√°s libertad para ajustar la curva.
* Us√© un valor de $\alpha$ que funcionara bien y un n√∫mero razonable de iteraciones (basado en c√≥mo se ve la curva de p√©rdida).

Todo esto me permiti√≥ entrenar el modelo y practicar la funci√≥n `predict`.

### Visualizaci√≥n del entrenamiento

Compar√© la evoluci√≥n del error y el efecto de distintos valores de $\alpha$:

![Curva de p√©rdida vs iteraciones](Regresion_Logisitica/Figure_2.png)

![Comparaci√≥n de tasas de aprendizaje](Regresion_Logisitica/Figure_1.png)

---

## ‚úÖ Funci√≥n predecir

Con la hip√≥tesis $h_\theta(x)$, calculamos probabilidades y luego usamos un **umbral** de 0.5 para convertir eso en una decisi√≥n:

* Si $h_\theta(x) \geq 0.5$ ‚Üí predice clase **1**.
* Si $h_\theta(x) < 0.5$ ‚Üí predice clase **0**.

Esto nos da una predicci√≥n binaria clara.

---

## üéØ Accuracy del modelo

Para saber qu√© tan bien aprendi√≥ el modelo, calcul√© el **accuracy**, que es el porcentaje de predicciones correctas.

En este caso, obtuve:

$$
\text{Accuracy} = 97.01\%
$$

Tambi√©n prob√© una forma alternativa de calcularlo con menos pasos, solo para recordar que se puede hacer lo mismo de distintas maneras.

---




## ü§î ¬øPor qu√© usamos la entrop√≠a cruzada binaria? (BCE vs MSE)

Usamos la **entrop√≠a cruzada binaria** (BCE) en regresi√≥n log√≠stica porque se ajusta muy bien al funcionamiento de la **funci√≥n sigmoide**, que nos da una probabilidad entre 0 y 1. En problemas de clasificaci√≥n binaria, como este, donde solo existen dos posibles clases (0 o 1), la BCE se adapta perfectamente, ya que estamos modelando **probabilidades**.

La BCE tiene la ventaja de penalizar m√°s fuertemente cuando el modelo se equivoca, especialmente cuando est√° muy seguro de su predicci√≥n y se equivoca. Esto ayuda a que el modelo aprenda m√°s r√°pido y mejor. En cambio, el **error cuadr√°tico medio** (MSE) no penaliza de la misma manera y no se comporta tan bien cuando estamos trabajando con **probabilidades**, ya que no mide la calidad de las predicciones de manera tan eficiente como la BCE.

En resumen, la BCE es m√°s adecuada para este tipo de problemas, porque no solo mide la diferencia entre las predicciones y las clases reales, sino que tambi√©n penaliza m√°s fuertemente los errores cuando el modelo est√° muy confiado y equivocado.

## Cuadro comparativo entre BCE y MSE

| **Caracter√≠stica**          | **Entrop√≠a Cruzada Binaria (BCE)**                                                              | **Error Cuadr√°tico Medio (MSE)**                                                                |
| --------------------------- | ----------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------- |
| **Uso principal**           | Problemas de clasificaci√≥n binaria (0 o 1)                                                      | Problemas de regresi√≥n (predicciones continuas)                                                 |
| **Salida del modelo**       | Probabilidades (0 a 1)                                                                          | Cualquier valor real (n√∫meros continuos)                                                        |
| **F√≥rmula**                 | $-y \log(h) - (1 - y) \log(1 - h)$                                                              | $\frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2$                                                  |
| **Qu√© mide**                | Cu√°nta "sorpresa" hay entre la predicci√≥n y el valor real                                       | La diferencia entre la predicci√≥n y el valor real                                               |
| **Penalizaci√≥n de errores** | Penaliza fuertemente los errores de alta certeza (predicciones incorrectas con mucha confianza) | Penaliza m√°s los errores grandes, pero no lo suficiente para problemas de clasificaci√≥n binaria |
| **Ventajas**                | Se ajusta a problemas binarios, es estad√≠sticamente coherente, y ayuda al aprendizaje eficiente | Es simple y f√°cil de calcular, pero no es adecuado para probabilidades                          |
| **Desventajas**             | No es adecuado para regresi√≥n, y puede ser sensible a valores muy extremos                      | No es ideal para clasificaci√≥n binaria, ya que no maneja bien las probabilidades                |

---

## **Resumen f√°cil**:

* **BCE** es la mejor opci√≥n cuando est√°s trabajando con **probabilidades y clasificaci√≥n binaria** (0 o 1).
* **MSE** es mejor para **predicciones continuas** (por ejemplo, en regresi√≥n), pero no se adapta bien a los problemas de probabilidad.
---

## ü§î ¬øQu√© significa que una funci√≥n de coste sea "no convexa"?

Si usamos **MSE** (Error Cuadr√°tico Medio) en lugar de **BCE** (Entrop√≠a Cruzada Binaria), la funci√≥n de coste puede volverse **no convexa**. Esto sucede porque el **MSE** no se ajusta tan bien a la funci√≥n sigmoide, y puede generar una funci√≥n de coste con **m√∫ltiples m√≠nimos locales**. Esto dificulta encontrar el mejor valor para los par√°metros del modelo.

El **descenso de gradiente** es un algoritmo que busca minimizar la funci√≥n de coste, es decir, encuentra el m√≠nimo de la funci√≥n para que el modelo sea lo m√°s preciso posible.

### ¬øQu√© significa que una funci√≥n de coste sea "convexa"?

Cuando una funci√≥n es **convexa**, tiene una forma de **cuenco** o "U". En este caso, la funci√≥n solo tiene un **m√≠nimo global** (el fondo del cuenco), y no hay otros **picos** o "colinas" que distraigan el proceso de b√∫squeda del m√≠nimo.

Cuando la funci√≥n es convexa, **el descenso de gradiente** siempre llevar√° al **m√≠nimo global**. No importa desde qu√© punto empieces, siempre ir√°s hacia el punto m√°s bajo de la funci√≥n.

### ¬øQu√© pasa si la funci√≥n de coste no es convexa?

Si la funci√≥n **no es convexa** (como sucede con el **MSE** en regresi√≥n log√≠stica), entonces la funci√≥n de coste puede tener **m√∫ltiples m√≠nimos locales** (como monta√±as y valles). El **descenso de gradiente** podr√≠a quedarse atrapado en un **m√≠nimo local** y no encontrar el mejor valor (m√≠nimo global).

---

### üèûÔ∏è Ejemplo Visual

**Funci√≥n Convexa (como BCE):**

Imagina que est√°s en un campo con una sola gran colina que desciende en todas direcciones (funci√≥n convexa). No importa en qu√© punto empieces, siempre **descender√°s** hacia el punto m√°s bajo, que es el **m√≠nimo global**.

**Funci√≥n No Convexa (como MSE):**

Ahora imagina un campo con varias monta√±as y valles (funci√≥n no convexa). Si te encuentras en un valle peque√±o (m√≠nimo local), podr√≠as pensar que has encontrado el mejor lugar. Sin embargo, hay un valle m√°s profundo en otro lugar, el **m√≠nimo global**. Si el descenso de gradiente se queda atrapado en el primer valle, no podr√° encontrar el m√≠nimo global.

---

### üìù Resumen en palabras sencillas:

El **descenso de gradiente** busca el punto m√°s bajo (m√≠nimo) de una **funci√≥n de coste** ajustando los par√°metros del modelo.

* Si la funci√≥n es **convexa** (como la BCE), el descenso de gradiente siempre encontrar√° el **m√≠nimo global**.
* Si la funci√≥n es **no convexa** (como con MSE en regresi√≥n log√≠stica), el descenso de gradiente podr√≠a quedarse atrapado en **m√≠nimos locales** y no encontrar el mejor m√≠nimo global.

---




## üìå ¬øPor la que la Entrop√≠a Cruzada Binaria (BCE) es "la elegida" para modelos como la Regresi√≥n Log√≠stica.  (Conexi√≥n con MLE)

Una de las razones m√°s importantes para usar la **Entrop√≠a Cruzada Binaria (BCE)** en regresi√≥n log√≠stica es que **est√° directamente relacionada con un principio estad√≠stico muy fuerte llamado *Estimaci√≥n de M√°xima Verosimilitud (MLE)*.**



## üìö Fundamento Te√≥rico de la Entrop√≠a Cruzada Binaria en Regresi√≥n Log√≠stica

### ‚ùì ¬øPor qu√© usamos Entrop√≠a Cruzada Binaria (Binary Cross-Entropy, BCE) como funci√≥n de coste?

Adem√°s de ser √∫til en la pr√°ctica, la Entrop√≠a Cruzada Binaria tiene una **base te√≥rica muy s√≥lida** que la hace especialmente adecuada para la regresi√≥n log√≠stica.

---

### üéØ Objetivo del modelo

La regresi√≥n log√≠stica busca predecir la **probabilidad** de que algo ocurra (por ejemplo, que un correo sea spam o no). Por eso usamos la **funci√≥n sigmoide**, que transforma cualquier n√∫mero en un valor entre 0 y 1, justo lo que necesitamos para representar probabilidades:

$$
h_Œ∏(x) = \frac{1}{1 + e^{-Œ∏^T x}}
$$

---

### üß™ ¬øQu√© hace la Entrop√≠a Cruzada?

La funci√≥n de coste BCE mide **qu√© tan buena es la probabilidad** que el modelo asigna a los resultados reales. Penaliza m√°s fuertemente cuando el modelo est√° muy seguro pero se equivoca (por ejemplo, predice 0.99 pero el resultado real es 0).

La f√≥rmula general de la **Entrop√≠a Cruzada Binaria** es:

$$
J(Œ∏) = -\frac{1}{m} \sum_{i=1}^{m} \left[ y^{(i)} \log(h_Œ∏(x^{(i)})) + (1 - y^{(i)}) \log(1 - h_Œ∏(x^{(i)})) \right]
$$

---

### üìê Base te√≥rica: Estimaci√≥n por M√°xima Verosimilitud (MLE)

Matem√°ticamente, **minimizar la BCE es lo mismo que buscar los valores de $Œ∏$ que hacen m√°s probable que los datos reales ocurran**. Esto se llama:

> **Estimaci√≥n por M√°xima Verosimilitud (MLE)**

En otras palabras:

* El modelo no solo trata de acertar.
* Intenta asignar **altas probabilidades a los eventos correctos**.
* Esto lo alinea naturalmente con la funci√≥n sigmoide, que **ya devuelve probabilidades**.

---

### üß© En resumen:

* ‚úÖ La BCE es coherente con el objetivo probabil√≠stico de la regresi√≥n log√≠stica.
* üß† Tiene un fuerte respaldo matem√°tico (MLE).
* üìâ Castiga con m√°s fuerza cuando el modelo se equivoca con seguridad.
* ü§ù Hace que entrenar el modelo sea una cuesti√≥n de **ajustar las probabilidades, no solo de acertar o fallar**.



---

### üß† ¬øQu√© busca la MLE?

Queremos encontrar los par√°metros del modelo, representados como **Œ∏**, que hagan que los **datos de entrenamiento que ya observamos** (las verdaderas etiquetas `y`) sean **lo m√°s probables posible** seg√∫n el modelo. Es decir, que nuestro modelo diga:

> "¬°S√≠, con estos par√°metros, es muy probable que haya visto exactamente estos datos!"

---


### üìä ¬øC√≥mo se calcula esa probabilidad?

Para una sola observaci√≥n $(x^{(i)}, y^{(i)})$, la probabilidad seg√∫n el modelo es:

* Si $y^{(i)} = 1$, entonces la probabilidad es $h_{\theta}(x^{(i)})$
* Si $y^{(i)} = 0$, entonces la probabilidad es $1 - h_{\theta}(x^{(i)})$

Todo esto se puede escribir as√≠:

$$
P(y^{(i)}|x^{(i)};\theta) = (h_{\theta}(x^{(i)}))^{y^{(i)}} (1 - h_{\theta}(x^{(i)}))^{1 - y^{(i)}}
$$

> *Compru√©balo t√∫ mismo: si y = 1, queda solo hŒ∏(x); si y = 0, queda 1 ‚àí hŒ∏(x)*.

---

### üì¶ Verosimilitud total (Likelihood)

Ya que asumimos que las observaciones son independientes, multiplicamos todas las probabilidades:

$$
L(\theta) = \prod_{i=1}^{m} P(y^{(i)}|x^{(i)};\theta)
$$

---

### üìà Log-Verosimilitud

Trabajar con productos es inc√≥modo, as√≠ que tomamos el logaritmo (para convertir productos en sumas):

$$
\log L(\theta) = \sum_{i=1}^{m} \left[ y^{(i)} \log(h_{\theta}(x^{(i)})) + (1 - y^{(i)}) \log(1 - h_{\theta}(x^{(i)})) \right]
$$

---

### üí° ¬°Sorpresa! ¬°Esta f√≥rmula ya la conoces!

La funci√≥n de coste de **Entrop√≠a Cruzada Binaria (BCE)** es exactamente la **negaci√≥n** del promedio de esa log-verosimilitud:

$$
J(\theta) = -\frac{1}{m} \sum_{i=1}^{m} \left[ y^{(i)} \log(h_{\theta}(x^{(i)})) + (1 - y^{(i)}) \log(1 - h_{\theta}(x^{(i)})) \right]
$$

---

### üß† En resumen:

* Maximizar la log-verosimilitud (objetivo de MLE) es **equivalente a minimizar la funci√≥n BCE**.
* El signo negativo y el factor $\frac{1}{m}$ solo convierten el problema de maximizar en uno de **minimizaci√≥n promedio**, que es justo lo que usa el **descenso de gradiente**.
* Esto le da a la BCE una base te√≥rica muy s√≥lida, **adem√°s de que es convexa** (lo cual es genial para evitar m√≠nimos locales).

---

### üìå Relaci√≥n entre la teor√≠a y la implementaci√≥n

#### 1. **Funci√≥n de hip√≥tesis `hŒ∏(x)`**

```python
def calcular_hipotesis(X, theta):
    Z_vector = X @ theta
    Z_vector_prob = sigmoid(Z_vector)
    return Z_vector_prob
```

Esta funci√≥n calcula **hŒ∏(x)**, que representa la **probabilidad** de que una muestra pertenezca a la clase 1. Esto es precisamente lo que necesita el MLE: una funci√≥n que d√© **probabilidades condicionales P(y|x;Œ∏)**.

---

#### 2. **Funci√≥n de coste `calcular_coste`**

```python
def calcular_coste(X, y, theta):
    ...
    coste = - (1 / m) * sum_total
    return coste
```

Esta es **exactamente** la f√≥rmula de la **Entrop√≠a Cruzada Binaria (BCE)**, que como dijimos en la teor√≠a, es la **forma negativa y promedio de la log-verosimilitud**:

* **MLE:** maximiza la log-verosimilitud.
* **BCE:** minimiza el coste (‚àílog-verosimilitud promedio).

Por eso, esta funci√≥n de coste **implementa MLE en forma negativa**, adaptada para optimizaci√≥n v√≠a descenso de gradiente.

---

#### 3. **Descenso de Gradiente**

```python
theta = theta - alpha * gradiente
```

### üß† En resumen 

### Justificaci√≥n estad√≠stica de la funci√≥n de coste

Una raz√≥n fundamental para utilizar la **Entrop√≠a Cruzada Binaria** en regresi√≥n log√≠stica es su s√≥lida base te√≥rica en la **Estimaci√≥n de M√°xima Verosimilitud (MLE)**. En este modelo, queremos encontrar los par√°metros Œ∏ que **maximicen la probabilidad de haber observado las etiquetas reales del entrenamiento**, dado nuestro modelo. Esto se logra **maximizando la log-verosimilitud**, la cual, al tomar su forma negativa y promedio, **se convierte en la funci√≥n de coste que usamos: la BCE**.

Por tanto, el proceso de entrenamiento (con `calcular_coste` y `descenso_gradiente`) **no solo busca minimizar un error arbitrario, sino que est√° directamente fundamentado en probabilidad y estad√≠stica**: est√° **maximizando la verosimilitud de los datos observados**.

---

# ADELANTO INVESTIGACION PARA SIGUIENTE TAREA:

---

## üß† ¬øEs la exactitud siempre la mejor m√©trica?

No. La **exactitud (accuracy)** solo mide el porcentaje de predicciones correctas. Pero en casos de **clases desbalanceadas**, puede dar una **falsa sensaci√≥n de buen rendimiento**.

### üìå Ejemplo cl√°sico:

Sup√≥n que estamos dise√±ando un test para una **enfermedad rara** que afecta al 1% de la poblaci√≥n.
De 1,000 personas, solo 10 la tienen.

Un modelo que **siempre predice "no tiene la enfermedad"** acertar√° en 990 casos.

* Exactitud = (990 aciertos) / 1000 = **99%**

¬°Parece genial! Pero‚Ä¶

* No detect√≥ **ni un solo caso verdadero**.
* **Recall = 0%**

Esto lo vuelve **in√∫til** para el prop√≥sito real: **detectar la enfermedad**.

---

## üß© Matriz de Confusi√≥n: ¬øQu√© significa cada caso?

Cuando entrenas un modelo para clasificar entre dos opciones (por ejemplo, **"enfermo"** o **"no enfermo"**), hay cuatro formas posibles en las que tu predicci√≥n puede coincidir (o no) con la realidad:

| Nombre üìå                     | Realidad üß† | Predicci√≥n ü§ñ       | ¬øQu√© pas√≥?                                                                                        |
| ----------------------------- | ----------- | ------------------- | ------------------------------------------------------------------------------------------------- |
| ‚úÖ **Verdadero Positivo (TP)** | 1 (Enfermo) | 1 (Predijo enfermo) | El paciente **ten√≠a la enfermedad** y el modelo **lo detect√≥ correctamente**. Perfecto.           |
| ‚úÖ **Verdadero Negativo (TN)** | 0 (Sano)    | 0 (Predijo sano)    | El paciente **no ten√≠a la enfermedad** y el modelo **tambi√©n dijo que no**. Muy bien.             |
| ‚ö†Ô∏è **Falso Positivo (FP)**    | 0 (Sano)    | 1 (Predijo enfermo) | El paciente **estaba sano**, pero el modelo **dijo que estaba enfermo**. Una **falsa alarma**.    |
| ‚ùå **Falso Negativo (FN)**     | 1 (Enfermo) | 0 (Predijo sano)    | El paciente **s√≠ ten√≠a la enfermedad**, pero el modelo **no la detect√≥**. El error **m√°s grave**. |

---

### üß† ¬øPor qu√© son importantes?

* **TP y TN** son los **aciertos** del modelo.
* **FP y FN** son los **errores**.
* A partir de ellos, se calculan m√©tricas como **precisi√≥n**, **recall** y **F1-score**, que permiten entender mejor c√≥mo se comporta el modelo en **situaciones cr√≠ticas**.

---

¬øQuieres que agregue una visualizaci√≥n estilo matriz con estos valores colocados en una tabla tipo cuadr√≠cula (como un diagrama)?


## üìå M√©tricas clave

### üéØ Precisi√≥n (Precision)

> ¬øDe los que dije que eran positivos, cu√°ntos lo eran realmente?

**F√≥rmula:**
**Precisi√≥n = TP / (TP + FP)**

**Importante cuando:** El coste de un **falso positivo** es alto.
**Ejemplos:**

* Clasificaci√≥n de spam
* Recomendaciones de productos
* Sistema judicial (condenar a un inocente)

---

### üîç Recall (Sensibilidad, Exhaustividad)

> ¬øDe todos los que realmente eran positivos, cu√°ntos detect√©?

**F√≥rmula:**
**Recall = TP / (TP + FN)**

**Importante cuando:** El coste de un **falso negativo** es alto.
**Ejemplos:**

* Detecci√≥n de enfermedades graves
* Fraude bancario
* Alerta temprana de incendios o cat√°strofes

---

### ‚öñÔ∏è F1-Score (Balance entre precisi√≥n y recall)

> ¬øC√≥mo consigo un equilibrio justo entre precisi√≥n y recall?

**F√≥rmula:**
**F1 = 2 \* (Precision \* Recall) / (Precision + Recall)**

* Es la **media arm√≥nica**: si una m√©trica es baja, el F1 tambi√©n ser√° bajo.
* √ötil con **clases desbalanceadas**, o cuando es importante tener un **buen balance**.

---


Siguiendo con el ejemplo de la **enfermedad rara** (donde el 1% tiene la enfermedad y el 99% no):

Imagina que tenemos un modelo que **siempre predice "no tiene la enfermedad"**:

| **Resultado**               | **Realidad** | **Predicci√≥n** | **Cantidad** |
| --------------------------- | ------------ | -------------- | ------------ |
| **Verdadero Positivo (TP)** | 1            | 1              | 0            |
| **Falso Positivo (FP)**     | 0            | 1              | 0            |
| **Falso Negativo (FN)**     | 1            | 0              | 10           |
| **Verdadero Negativo (TN)** | 0            | 0              | 990          |

### **Accuracy**:

La **Accuracy** se calcula como:

**Accuracy** = (TP + TN) / Total = (0 + 990) / 1000 = **99%**
¬°Una **Accuracy** del 99%, que parece excelente!

---

Sin embargo, si nos fijamos en **Recall** para la clase **"tiene la enfermedad"**, vemos lo siguiente:

### **Recall (Sensibilidad)**:

**Recall** = TP / (TP + FN) = 0 / (0 + 10) = **0%**
Esto significa que el modelo **no detecta ninguna persona enferma**, lo cual hace que **no sea √∫til para el diagn√≥stico** de la enfermedad.

---
## ‚úÖ Conclusi√≥n

* Usa **Accuracy** solo si las clases est√°n balanceadas.
* Usa **Precisi√≥n** si **falsos positivos** son costosos.
* Usa **Recall** si **falsos negativos** son peligrosos.
* Usa **F1-Score** cuando **ambos errores son cr√≠ticos** o cuando hay **desequilibrio de clases**.
---


### ‚úÖ **¬øC√≥mo resumir la utilidad de Precisi√≥n, Recall y F1-Score?**

* **Precisi√≥n** te dice:

  > ‚Äú¬øCu√°ntos de los que el modelo **dijo que eran positivos**, **realmente lo eran**?‚Äù
  > Es √∫til cuando **no quieres dar falsas alarmas** (falsos positivos).
  > Ejemplo: Un filtro de spam ‚Äî mejor no meter correos importantes en la carpeta de spam.

* **Recall** te dice:

  > ‚Äú¬øCu√°ntos de los que **realmente eran positivos**, **logramos detectar**?‚Äù
  > Es √∫til cuando **no quieres dejar pasar casos importantes** (falsos negativos).
  > Ejemplo: Diagn√≥stico de una enfermedad ‚Äî mejor detectar todos los casos posibles, aunque te equivoques con algunos sanos.

* **F1-Score**:

  > Es una media entre precisi√≥n y recall.
  > Es √∫til cuando hay **desbalance de clases** o cuando **necesitas un equilibrio** entre no dar falsas alarmas y no dejar pasar casos.
  > Ejemplo: Detecci√≥n de fraude ‚Äî necesitas capturar la mayor√≠a de fraudes (recall), pero tambi√©n evitar acusar a gente inocente (precisi√≥n).

---

### üß† **¬øPor qu√© el F1-Score intenta balancearlas?**

Porque en muchos problemas **no basta con solo precisi√≥n o solo recall**. Si una es muy alta y la otra muy baja, el modelo puede estar fallando en algo importante.
**F1 te obliga a que ambas sean razonablemente buenas.**

---

## ‚úÇÔ∏è Implementaci√≥n de `train_test_split` en Regresi√≥n Log√≠stica

Al usar `train_test_split` de `sklearn.model_selection`, dividimos el conjunto de datos original en dos subconjuntos:

* **X\_train, y\_train**: usados para entrenar el modelo.
* **X\_test, y\_test**: usados exclusivamente para evaluarlo.

Esta divisi√≥n permite medir el rendimiento real del modelo sobre datos **no vistos**, lo cual es crucial para evitar una evaluaci√≥n sesgada. Evaluar el modelo sobre los mismos datos de entrenamiento puede resultar en:

* Una estimaci√≥n **excesivamente optimista** de su rendimiento.
* Riesgo de **overfitting**, donde el modelo memoriza los datos en lugar de aprender patrones generalizables.

---

## üéØ ¬øQu√© nos permite esta divisi√≥n?

Gracias a `train_test_split`, podemos:

‚úÖ Evaluar **c√≥mo generaliza** el modelo a nuevos datos.
üìä Calcular m√©tricas de clasificaci√≥n clave, como:

* **Accuracy** (exactitud)
* **Matriz de Confusi√≥n**
* **Precision**
* **Recall**
* **F1 Score**

