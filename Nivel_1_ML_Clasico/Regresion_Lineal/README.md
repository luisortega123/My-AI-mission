# Regresi√≥n Lineal

## ¬øQu√© es?

La **regresi√≥n lineal** es una t√©cnica estad√≠stica que busca la relaci√≥n entre una variable cuantitativa ($Y$) y una o m√°s variables predictoras ($X$).
El **objetivo** es **predecir valores num√©ricos continuos**, bas√°ndose en la suposici√≥n de que existe una relaci√≥n lineal entre las variables explicativas ($X$) y la variable objetivo ($Y$).

---

## ¬øQu√© tipo de resultado produce?

**Variable cuantitativa continua:**
No clasifica en categor√≠as, sino que entrega un valor num√©rico que puede tomar cualquier valor dentro de un rango.

---

## Interpretaci√≥n de los coeficientes

Los coeficientes del modelo ($\theta$) indican c√≥mo cambia $Y$ ante variaciones en $X$.

---

## Funci√≥n Hip√≥tesis ($h_\theta(X) = X \theta$)

Ecuaci√≥n fundamental en la regresi√≥n lineal: $h_\theta(X) = X \theta$. Define la relaci√≥n entre las variables predictoras ($X$) y la variable objetivo ($Y$).

### Objetivo

Predecir valores num√©ricos continuos bas√°ndose en una combinaci√≥n lineal de caracter√≠sticas de entrada y coeficientes asociados.

### Elementos

1.  **$X$**: Matriz de caracter√≠sticas (inputs)
    * Cada fila representa una observaci√≥n (ejemplo de entrenamiento)
    * Cada columna corresponde a una caracter√≠stica (variable predictora)
    * Se agrega una columna de unos para incluir el intercepto ($\theta_0$)

2.  **$\theta$**: Vector de par√°metros (coeficientes)
    * Contiene los pesos que el modelo aprende durante el entrenamiento
    * Incluye el intercepto ($\theta_0$)
    * $\theta_1, \theta_2, \dots$ indican la influencia de cada caracter√≠stica

3.  **$h_\theta(X)$**: Predicci√≥n del modelo
    * Resultado del producto matricial $X\theta$
    * Cada valor $h_\theta(x^{(i)})$ es la predicci√≥n para la observaci√≥n $i$

---

## Funci√≥n de Coste (MSE)

**F√≥rmula:**
$J(\theta) = \frac{1}{2m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})^2$

Mide el **promedio del error cuadr√°tico** entre las predicciones del modelo y los valores reales en todo el conjunto de datos.

* **$m$**: N√∫mero de observaciones
* **$h_\theta(x^{(i)})$**: Predicci√≥n para la observaci√≥n $i$
* **$y^{(i)}$**: Valor real para la observaci√≥n $i$

---

### ¬øPor qu√© se eleva al cuadrado la diferencia?

1.  **Evita errores negativos:** Las diferencias se vuelven positivas.
2.  **Penaliza errores grandes:** Un error de 2 pesa m√°s (4) que uno de 1 (1).
3.  **Facilita la optimizaci√≥n:** La funci√≥n cuadr√°tica es convexa y garantiza un m√≠nimo global.

---

## ¬øPor qu√© queremos minimizar $J(\theta)$?

Minimizar $J(\theta)$ significa ajustar los par√°metros $\theta$ para que las predicciones sean lo m√°s cercanas posible a los valores reales.

### M√©todos comunes:

* **M√≠nimos Cuadrados Ordinarios (OLS):** Soluci√≥n anal√≠tica.
* **Descenso de Gradiente (GD):** M√©todo iterativo.

---

## ¬øQu√© implica un $J(\theta)$ peque√±o?

* **Buen ajuste:** Las predicciones est√°n cerca de los valores reales.
* **Alta precisi√≥n:** El modelo generaliza bien.
* **Menor incertidumbre:** Los errores (residuos) tienen baja variabilidad.

---

# Descenso de Gradiente (Gradient Descent)

El **descenso de gradiente** busca minimizar $J(\theta)$, ajustando iterativamente los par√°metros $\theta$ para reducir el error.

### En resumen:

Es un m√©todo que permite a un modelo **aprender** los mejores valores de los par√°metros $\theta$, optimizando la predicci√≥n. El resultado del entrenamiento es el vector `theta_final`, que contiene los coeficientes √≥ptimos encontrados por el modelo.

---

## Regla de Actualizaci√≥n

$\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta)$ (Esta es la regla impl√≠cita que se describe)

### Componentes

**$\alpha$ (Tasa de Aprendizaje):**

* Controla el tama√±o del paso en cada iteraci√≥n.
* $\alpha$ alto ‚Üí puede hacer que el algoritmo no converja.
* $\alpha$ bajo ‚Üí puede hacer que la convergencia sea muy lenta.

**Derivada Parcial ($\frac{\partial}{\partial \theta_j} J(\theta)$):**

* Mide la direcci√≥n de mayor aumento de $J(\theta)$
* Al restarla, el modelo se mueve en direcci√≥n descendente (hacia el m√≠nimo).

---

## Gradiente Vectorizado

**F√≥rmula:**
$\nabla J(\theta) = \frac{1}{m} X^T (X\theta - y)$

### T√©rminos

1.  **$X\theta$**: Vector de predicciones para todas las observaciones.
2.  **$X\theta - y$**: Vector de errores residuales.
3.  **$X^T$**: Multiplicaci√≥n por la transpuesta de $X$ pondera los errores por cada caracter√≠stica.
4.  **$\frac{1}{m}$**: Promedia el gradiente sobre el conjunto de datos.

---

## ¬øQu√© representa el resultado?

El vector $\nabla J(\theta)$ nos dice:

* **Direcci√≥n:**
    * Si $\frac{\partial J}{\partial \theta_j} > 0$ = disminuir $\theta_j$
    * Si $\frac{\partial J}{\partial \theta_j} < 0$ = aumentar $\theta_j$

* **Magnitud:**
    * Cu√°nto influye ese $\theta_j$ en el error total

---

## Resumen

* **Objetivo:** Minimizar $J(\theta)$ ajustando $\theta$ para reducir errores
* **Tasa de Aprendizaje ($\alpha$):** Controla la velocidad de convergencia
* **Gradiente Vectorizado:** Forma eficiente de calcular el ajuste de todos los coeficientes a la vez

# üìò Pasos del Algoritmo de Regresi√≥n Lineal (California Housing)

## 1. üóÇÔ∏è Importaci√≥n de Datos

Importamos el dataset **California Housing** y las funciones necesarias de **NumPy**.

* `.data`: contiene las **caracter√≠sticas** (features), en forma de matriz ($X$).
* `.target`: contiene los **valores a predecir** (precios promedio de casas) ($Y$).

Se ajust√≥ la forma de $Y$ usando `np.reshape` para trabajar con matrices columna, sin alterar los datos.

---

## 2. ‚öñÔ∏è Normalizaci√≥n (Estandarizaci√≥n)

Calculamos la **media ($\mu$)** y **desviaci√≥n est√°ndar ($\sigma$)** de los datos originales para escalar las caracter√≠sticas. Esto es clave porque:

* Las variables originales tienen diferentes escalas.
* Sin escalar, el descenso de gradiente puede ser lento o ineficaz.
* El escalado mejora la velocidad y estabilidad del entrenamiento.
kv
**üîß Sin este paso, el modelo devolv√≠a `null` en `theta_final`, sin importar los hiperpar√°metros.**

---

## 3. ‚ûï Agregar Columna de Unos (Bias)

Se a√±adi√≥ una columna de unos a `X_scaled` para permitir que el modelo aprenda un **t√©rmino independiente** ($\theta_0$), haciendo que la recta **no tenga que pasar por el origen (0,0)**.
Esto da **flexibilidad** al modelo.

---

## 4. üîÆ Funci√≥n de Hip√≥tesis

Se implement√≥ la funci√≥n `calcular_hipotesis(X, theta)`:

* Predice valores continuos.
* Es la base de la f√≥rmula de **regresi√≥n lineal**:
    $h(\theta) = X \theta$

---

## 5. ‚ùå Funci√≥n de Coste (MSE)

Se implement√≥ la funci√≥n de coste: **Error Cuadr√°tico Medio (Mean Squared Error)**. $J(\theta)$.

Mide el **promedio del error al cuadrado** entre predicciones ($h_\theta(x^{(i)})$) y valores reales ($y^{(i)}$).

üìâ El objetivo es **minimizarla**:

* **MSE alta** ‚Üí el modelo se equivoca mucho.
* **MSE baja** ‚Üí el modelo est√° aprendiendo bien.

---

## 6. üîÅ Descenso de Gradiente

Se implement√≥ el **descenso de gradiente** para minimizar el error:

* Calcula predicciones, errores y gradiente ($\nabla J(\theta)$) en cada iteraci√≥n.
* Actualiza $\theta$ con la regla de aprendizaje:
    $\theta := \theta - \alpha \nabla J(\theta)$

Se definieron:

* `theta_inicial`: vector de ceros
* $\theta$ (tasa de aprendizaje)
* `n_iteraciones`

Tambi√©n se grafic√≥ el **historial de coste** para visualizar la convergencia del algoritmo.
![alt text](<Regresion_Lineal.py/Grafico Historial de coste.png>)
**La gr√°fica mostr√≥ que el coste convergi√≥ de forma estable a un valor aproximado de X.XX despu√©s de unas YYY iteraciones.** (<- **¬°RECUERDA REEMPLAZAR X.XX e YYY con tus valores!**)

---

## 7. ü§ñ Funci√≥n de Predicci√≥n

La funci√≥n `predecir(X_nuevos, theta_final, mu, sigma)` permite usar el modelo entrenado con **nuevos datos**:

1.  Escala los nuevos datos con $\mu$ y $\sigma$ del entrenamiento.
2.  A√±ade la columna de unos (bias).
3.  Aplica la f√≥rmula de regresi√≥n lineal ($h_\theta(X) = X \theta$) para predecir precios.

---

## ‚úÖ Conclusi√≥n

Este modelo permite predecir el precio promedio de casas en California usando regresi√≥n lineal multivariable, correctamente entrenada y escalada.
Con el descenso de gradiente y la MSE como gu√≠a, podemos ajustar $\theta$ hasta encontrar una soluci√≥n eficiente y precisa.

## Punto 1: Consolidar el Aprendizaje üß†

Dependiendo del valor de **alpha**, podemos observar cu√°nto tiempo tarda en **converger** el algoritmo.

* Si el **alpha es muy peque√±o**, el descenso de gradiente avanza muy lento.
* Si el **alpha es muy grande**, el algoritmo puede **omitir el aprendizaje** o incluso **divergir** (los valores crecen en lugar de estabilizarse).

üìà
*Figura 1*
![alt text](Regresion_Lineal.py/Figure_1.png)

Gracias a la comparaci√≥n de los valores en la gr√°fica, podemos encontrar un **alpha ideal**:


üìâ
*Figura 2*
![alt text](Regresion_Lineal.py/Figure_2.png)


Sin el **escalado**, el descenso de gradiente tarda m√°s o simplemente **no converge** (pueden aparecer datos 'null').
En cambio, cuando **escalamos las caracter√≠sticas**:

* Las variables tienen una magnitud parecida.
* El algoritmo avanza mejor.
* Se pueden usar valores de alpha m√°s grandes sin que se vuelva inestable.
* Todo converge de forma m√°s r√°pida y eficiente.


*Gr√°fico del historial de coste*
![alt text](<Regresion_Lineal.py/Grafico Historial de coste.png>)


### ‚úÖ En resumen:

* Escalar las caracter√≠sticas mejora la **eficiencia del algoritmo**.
* Elegir bien el valor de **alpha** hace que el modelo **converja m√°s r√°pido** sin salirse de control.

##  Punto 2: Evaluar el N√∫mero de Iteraciones ‚è±Ô∏è

Con distintos valores de alpha, podemos observar que, aproximadamente a partir de las 2500 iteraciones, las curvas comienzan a aplanarse. Esto indica que el algoritmo empieza a converger, ya que el coste deja de disminuir significativamente.

En mi experimento utilic√© 4000 iteraciones como n√∫mero total. Eleg√≠ este valor porque, al probar varios valores de alpha, quer√≠a asegurarme de observar con claridad en qu√© punto cada curva se aplanaba por completo. Esto me permiti√≥ identificar con mayor precisi√≥n cu√°ndo el algoritmo realmente comenzaba a converger en cada caso.

![alt text](Regresion_Lineal.py/Figure_1.2.png)



# Regresi√≥n Lineal: Ecuaci√≥n Normal vs Descenso de Gradiente  

## Estructura de la Matriz **X** y el Vector **y**  
### **Matriz X (Dise√±o)**  
- **Contenido**:  
  - Columna de **unos (1)** para el intercepto (`Œ∏‚ÇÄ`).  
  - Columnas de **caracter√≠sticas** (`X‚ÇÅ, X‚ÇÇ, ..., X‚Çô`).  
- **Dimensiones**:  
  `m √ó (n+1)`  *(m observaciones, n caracter√≠sticas)*  

### **Vector y (Objetivo)**  
- **Contenido**: Valores reales a predecir.  
- **Dimensiones**:  
  `m √ó 1`  

## üîç **Comparaciones Clave**  
### üìä Resultados Experimentales  
| **Escenario**            | Diferencia (Error) | Comparaci√≥n V√°lida |  
|--------------------------|--------------------|--------------------|  
| Theta GD (escalado) vs Theta EN (**sin escalar**) | ‚âà 111              | ‚ùå No (escalas distintas) |  
| Theta GD (escalado) vs Theta EN (**escalado**)    | ‚âà 9.9              | ‚úÖ S√≠               |  

### ‚ùì **Interpretaci√≥n**  
1. **Diferencia ‚âà 111**:  
   - Ilustra c√≥mo el **escalado afecta los valores absolutos de `Œ∏`**.  
   - **No es v√°lida t√©cnicamente** (comparar `Œ∏` en escalas diferentes no tiene sentido matem√°tico).  

2. **Diferencia ‚âà 9.9**:  
   - Muestra que el Descenso de Gradiente (**GD**) **no convergi√≥ totalmente** por falta de iteraciones.  

---

## üßÆ **Ecuaci√≥n Normal: F√≥rmula e Implementaci√≥n**  
### **F√≥rmula Anal√≠tica**  


Œ∏ = (X·µó X)‚Åª¬π X·µó y



### **Pasos de Implementaci√≥n**  
1. Calcular `X·µó X`.  
2. Invertir la matriz resultante.  
3. Multiplicar por `X·µó y`.  

## ‚öñÔ∏è **Pros y Contras**  
| **M√©todo**           | **Ecuaci√≥n Normal**                              | **Descenso de Gradiente**                     |  
|----------------------|--------------------------------------------------|-----------------------------------------------|  
| **Ventajas**         | - Soluci√≥n exacta en 1 paso.<br>- Sin hiperpar√°metros.<br>- No requiere escalado. | - Escalable a grandes `n`.<br>- Funciona incluso si `X·µó X` es singular. |  
| **Desventajas**      | - Coste `O(n¬≥)` (lento para `n > 10‚Å¥`).<br>- Falla si `X·µó X` no es invertible. | - Necesita ajustar `Œ±` e iteraciones.<br>- Requiere escalado para converger bien. |  

---

## üöÄ **¬øCu√°ndo Usar Cada M√©todo?**  
| **Criterio**               | **Ecuaci√≥n Normal**          | **Descenso de Gradiente**       |  
|----------------------------|------------------------------|---------------------------------|  
| **N√∫mero de caracter√≠sticas** | `n < 10‚Å¥`                 | `n ‚â• 10‚Å¥`                      |  
| **Estabilidad matricial**  | Evitar si `X·µó X` es singular | Funciona siempre               |  
| **Recursos computacionales** | Adecuado para CPU/GPU moderadas | Ideal para clusters distribuidos |  

---

**Notas Finales**:  
- Usar `np.linalg.pinv` en lugar de `inv` para manejar matrices singulares.  
- El escalado en GD es **cr√≠tico** para convergencia r√°pida y estable.  


## üß™ Implementaci√≥n de `train_test_split` y Comparaci√≥n de M√©todos de Regresi√≥n

### ‚úÇÔ∏è Divisi√≥n del Dataset

Para mejorar la estructura y la organizaci√≥n del flujo de trabajo, implementamos la funci√≥n `train_test_split` de `sklearn.model_selection`. Esto nos permite separar claramente los datos de entrenamiento y prueba, y darles nombres consistentes como:

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=..., random_state=...)
```

Este cambio mejora la legibilidad y facilita la gesti√≥n de las variables a lo largo del c√≥digo.

---


## üìå ¬øQu√© hace `train_test_split` en regresi√≥n lineal?

Divide tus datos en:

* **Conjunto de entrenamiento (`X_train`, `y_train`)** ‚Üí se usa para ajustar los coeficientes del modelo (las "Œ∏").
* **Conjunto de prueba (`X_test`, `y_test`)** ‚Üí se usa para evaluar c√≥mo de bien generaliza el modelo a datos nuevos.

Esto evita que eval√∫es el modelo sobre los mismos datos con los que fue entrenado, lo que podr√≠a ocultar problemas como el **overfitting**.

---

## üìä M√©tricas comunes en regresi√≥n lineal

En vez de precisi√≥n o matriz de confusi√≥n (que son para clasificaci√≥n), usamos m√©tricas que miden **error num√©rico**:

### 1. **Mean Squared Error (MSE)**

Promedio del cuadrado de los errores:

$$
MSE = \frac{1}{n} \sum_{i=1}^{n}(y_i - \hat{y}_i)^2
$$

M√°s sensible a errores grandes.

---


### 2. **Mean Absolute Error (MAE)**

Promedio del valor absoluto de los errores:

$$
MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
$$

Menos sensible a valores extremos.

---

### 3. **R¬≤ Score (Coeficiente de determinaci√≥n)**

Indica qu√© tan bien se explica la variaci√≥n de los datos con el modelo (0 a 1, donde 1 es perfecto).

$$
R^2 = 1 - \frac{SSE}{SST}
$$

---

## üí¨ Entonces, en resumen:

> ‚ÄúEn regresi√≥n lineal, `train_test_split` permite evaluar el modelo en un conjunto independiente usando m√©tricas como MSE, MAE, RMSE y R¬≤, lo cual es esencial para validar su capacidad de generalizaci√≥n.‚Äù

---



### ‚öñÔ∏è Comparaci√≥n: Ecuaci√≥n Normal vs Descenso de Gradiente

Se observaron m√©tricas pr√°cticamente id√©nticas para ambos m√©todos en este dataset, lo que es esperable bajo ciertas condiciones:

* El **Descenso de Gradiente (GD)** fue aplicado sobre datos **escalados**.
* La **Ecuaci√≥n Normal (NE)** se aplic√≥ sobre datos **sin escalar**, como es est√°ndar cuando no se usa regularizaci√≥n.

Ambos m√©todos convergieron a soluciones **muy similares**, con diferencias menores en los decimales m√°s significativos. Por ejemplo:

| M√©todo | MSE (prueba) | Primeras 5 predicciones                   |
| ------ | ------------ | ----------------------------------------- |
| NE     | 0.5558915987 | \[0.7191, 1.7640, 2.7096, 2.8389, 2.6046] |
| GD     | 0.5558913314 | \[0.7191, 1.7640, 2.7096, 2.8389, 2.6046] |

Aunque los valores redondeados a 4 cifras son iguales (`0.5559`), un an√°lisis m√°s profundo muestra peque√±as diferencias, lo que indica que no son exactamente id√©nticos. Esto se visualiz√≥ claramente mediante un bloque de *debugging* con valores extendidos y predicciones parciales.

---

### üõ°Ô∏è Impacto de la Regularizaci√≥n: Cambio de Œª (lambda)

Durante la experimentaci√≥n con el par√°metro de regularizaci√≥n `Œª` (lambda) en el **Descenso de Gradiente**, se identificaron los siguientes comportamientos:

* Con **lambda = 0** o **valores muy peque√±os**, el algoritmo a veces **diverge**, especialmente si no se escalan las caracter√≠sticas y se usa una **tasa de aprendizaje alta** (`Œ± = 0.1`). Esto se manifiesta en la aparici√≥n de `nan` en los coeficientes (`theta`).
* Al **aumentar lambda** (por ejemplo, a 0.1 o m√°s), la **regularizaci√≥n L2 estabiliza** las actualizaciones penalizando los valores grandes de `theta`. Esto reduce la magnitud de los saltos del algoritmo y permite una convergencia m√°s estable, incluso sin escalado √≥ptimo.

> Esta observaci√≥n refuerza el papel de la regularizaci√≥n como herramienta no solo para evitar el sobreajuste, sino tambi√©n para **mejorar la estabilidad num√©rica** del aprendizaje en condiciones no ideales.

---

