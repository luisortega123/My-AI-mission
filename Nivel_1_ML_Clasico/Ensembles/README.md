# üå≥ √Årboles de Decisi√≥n

## üí° Concepto B√°sico
Los √°rboles de decisi√≥n segmentan el espacio de los predictores en regiones m√°s simples para realizar predicciones. Esto significa que dividen el conjunto de datos en subconjuntos o "regiones", bas√°ndose en distintas condiciones sobre los predictores. Los **predictores** (tambi√©n conocidos como **variables independientes**, **caracter√≠sticas** o **atributos**) son las variables de entrada que el modelo utiliza para realizar una predicci√≥n sobre una variable de salida (o variable dependiente).

## üõ†Ô∏è ¬øC√≥mo se Construyen los √Årboles? (Divisi√≥n Binaria Recursiva)
Este proceso se conoce como **Divisi√≥n Binaria Recursiva**. Es un enfoque que tiene dos caracter√≠sticas principales:

* **Descendente (Top-Down):** Comienza con todos los datos en una √∫nica regi√≥n (el nodo ra√≠z) y divide sucesivamente el espacio de predictores en subregiones m√°s peque√±as (nodos).
* **Codicioso (Greedy):** En cada paso, el algoritmo elige la mejor divisi√≥n posible *en ese momento espec√≠fico* (la que m√°s mejora un criterio local), sin considerar si una divisi√≥n que parece sub√≥ptima ahora podr√≠a conducir a un √°rbol globalmente mejor m√°s adelante.

## üìâ Criterios de Divisi√≥n para √Årboles de Regresi√≥n
En los √°rboles de regresi√≥n, el objetivo es predecir un valor continuo.

### Suma de Cuadrados de los Residuos (RSS)
El objetivo es encontrar un conjunto de regiones $R_1, \dots, R_J$ que minimicen la **Suma de Cuadrados de los Residuos (RSS)**:

$$
RSS = \sum_{j=1}^{J} \sum_{i \in R_j} \left( y_i - \hat{y}_{R_j} \right)^2
$$

üîç **Donde:**
* $y_i$ es el **valor real** de la observaci√≥n $i$.
* $\hat{y}_{R_j}$ es la **predicci√≥n** para la regi√≥n $R_j$. Com√∫nmente, es la **media de los valores de la variable respuesta** de las observaciones de entrenamiento que caen en esa regi√≥n.

### Proceso de Divisi√≥n
Para realizar la **divisi√≥n binaria recursiva**, en cada paso se selecciona un predictor $X_k$ y un punto de corte $s$. Esto divide el espacio en dos nuevas regiones:

* Regi√≥n 1: $\{ X \mid X_k < s \}$
* Regi√≥n 2: $\{ X \mid X_k \ge s \}$

El algoritmo busca el predictor $X_k$ y el punto de corte $s$ que logren la mayor reducci√≥n posible en el RSS. Espec√≠ficamente, se buscan $k$ y $s$ que minimicen la siguiente expresi√≥n (el RSS total despu√©s de la divisi√≥n):

$$
\sum_{i : x_i \in R_1(k, s)} (y_i - \hat{y}_{R_1})^2
\;+\;
\sum_{i : x_i \in R_2(k, s)} (y_i - \hat{y}_{R_2})^2
$$

üîç **Donde:**
* $x_i$ es la observaci√≥n n√∫mero $i$.
* $y_i$ es su valor real (variable respuesta).
* $\hat{y}_{R_1}$ y $\hat{y}_{R_2}$ son las predicciones (medias de la variable respuesta) en las regiones $R_1(k,s)$ y $R_2(k,s)$ respectivamente.

## üìä Criterios de Divisi√≥n para √Årboles de Clasificaci√≥n
En los √°rboles de clasificaci√≥n, el objetivo es predecir una categor√≠a o clase. La predicci√≥n para una observaci√≥n es la **clase m√°s frecuente** entre las observaciones de entrenamiento que se encuentran en la misma regi√≥n (nodo terminal) a la que pertenece la observaci√≥n.

En lugar del RSS, se utilizan otros criterios para realizar las divisiones:

### Tasa de Error de Clasificaci√≥n
Es la fracci√≥n de observaciones de entrenamiento en una regi√≥n que no pertenecen a la clase m√°s com√∫n en esa regi√≥n.

La f√≥rmula del error de clasificaci√≥n para una regi√≥n $m$ es:
$$
E_m = 1 - \max_c \left( \hat{p}_{mc} \right)
$$

üîç **Donde:**
* $\hat{p}_{mc}$ es la proporci√≥n de observaciones de entrenamiento en la regi√≥n $m$ que pertenecen a la clase $c$.
* $\max_c$ representa el valor m√°ximo entre todas las clases $c$.

> **Nota:** Aunque intuitivo, este criterio no es suficientemente sensible para guiar el crecimiento del √°rbol, ya que cambios peque√±os en las probabilidades de clase pueden no alterar la clase mayoritaria y, por ende, el error.

### √çndice de Gini
Mide la **pureza** de un nodo. Un valor peque√±o indica que el nodo contiene predominantemente observaciones de una sola clase (es decir, es m√°s "puro"). Se considera una medida de la "impureza" o "diversidad" de clases en un nodo.

El √≠ndice de Gini para una regi√≥n $m$ se calcula como:
$$`
G_m = \sum_{c=1}^{C} \hat{p}_{mc} \left(1 - \hat{p}_{mc} \right)
$$

üîç **Donde:**
* $\hat{p}_{mc}$ es la proporci√≥n de observaciones en la regi√≥n $m$ que pertenecen a la clase $c$.
* $C$ es el n√∫mero total de clases.

### Entrop√≠a (o Deviance)
La entrop√≠a es otra medida de la pureza de un nodo.

La entrop√≠a para una regi√≥n $m$ se define como:
$$
D_m = - \sum_{c=1}^{C} \hat{p}_{mc} \log_2 (\hat{p}_{mc})
$$

üîç **Donde:**
* $\hat{p}_{mc}$ es la proporci√≥n de observaciones en la regi√≥n $m$ que pertenecen a la clase $c$. Si $\hat{p}_{mc} = 0$ para alguna clase, el t√©rmino $\hat{p}_{mc} \log_2 (\hat{p}_{mc})$ se considera 0.
* $C$ es el n√∫mero total de clases.
* El logaritmo suele ser en base 2 (midiendo la informaci√≥n en bits), pero tambi√©n puede usarse el logaritmo natural.

Al igual que el √≠ndice de Gini, la entrop√≠a toma un valor peque√±o si las observaciones en el nodo pertenecen mayoritariamente a una sola clase (nodo puro).

> **Comparaci√≥n:** Tanto el **√≠ndice de Gini** como la **Entrop√≠a** son generalmente preferidos sobre la tasa de error de clasificaci√≥n para el crecimiento del √°rbol, ya que son m√°s sensibles a los cambios en las probabilidades de las clases en los nodos, lo que lleva a √°rboles m√°s informativos.

Gracias por compartir el texto. A continuaci√≥n te presento una **versi√≥n explicada en lenguaje claro**, seguida de una **reescritura optimizada del texto original**. He dividido la explicaci√≥n en dos grandes secciones:

---

# üå≥  Poda de √Årboles de Decisi√≥n

## ¬øPor qu√© podar un √°rbol?

Cuando entrenamos un √°rbol de decisi√≥n, si lo dejamos crecer sin l√≠mites, puede hacerse muy complejo. Esto significa que se ajusta demasiado bien a los datos con los que fue entrenado, incluso aprendiendo el "ruido" o las excepciones. A esto se le llama **sobreajuste (overfitting)**.

¬øY por qu√© es malo? Porque el √°rbol funcionar√° muy bien en los datos de entrenamiento, pero **fallar√° en predecir datos nuevos**.

### Soluci√≥n: podar el √°rbol

Una t√©cnica com√∫n es dejar que el √°rbol crezca mucho (lo llamamos **T‚ÇÄ**) y luego **recortarlo** o **podarlo** para obtener una versi√≥n m√°s simple que funcione mejor en general.

---

## ‚úÇÔ∏è ¬øC√≥mo se poda? Cost Complexity Pruning

En lugar de probar todas las formas posibles de recortar el √°rbol (lo cual ser√≠a lento y complejo), usamos un enfoque con un par√°metro llamado **Œ± (alfa)**.

### ¬øQu√© hace el par√°metro Œ±?

* Controla el equilibrio entre **el tama√±o del √°rbol** y **qu√© tan bien se ajusta a los datos**.
* Si **Œ± = 0**, no se penaliza el tama√±o y se queda el √°rbol completo.
* Si **Œ± es m√°s grande**, se prefieren √°rboles m√°s peque√±os, aunque cometan un poco m√°s de error.

### F√≥rmula usada:

La funci√≥n de costo que se quiere minimizar es:

$$\text{Costo}(T) = \underbrace{\sum_{m=1}^{|T|} \sum_{i \in R_m} (y_i - \hat{y}_{R_m})^2}_{\text{Error de Ajuste (RSS)}} + \underbrace{\alpha |T|}_{\text{Penalizaci√≥n por Complejidad}}$$

---

üîç **Explicaci√≥n Concisa de la F√≥rmula:**

Esta f√≥rmula calcula el "costo" de un sub√°rbol $T$, buscando el √°rbol que minimice este valor.

1.  **Error de Ajuste del √Årbol (RSS):**
    * $\underbrace{\sum_{m=1}^{|T|} \sum_{i \in R_m} (y_i - \hat{y}_{R_m})^2}_{\text{Error de Ajuste (RSS)}}$
    * Mide qu√© tan bien el √°rbol $T$ predice los datos de entrenamiento. Es la **Suma de los Cuadrados de los Residuos (RSS)**. Un valor bajo indica un mejor ajuste.
        * $\sum_{m=1}^{|T|} \sum_{i \in R_m}$: Suma sobre todas las **observaciones $i$** en todas las **hojas $m$** del √°rbol.
        * $y_i$: **Valor real** de la observaci√≥n $i$.
        * $\hat{y}_{R_m}$: **Predicci√≥n** del √°rbol para la hoja $R_m$ donde cae la observaci√≥n $i$.
        * $R_m$: La **regi√≥n (hoja)** $m$ del √°rbol.

2.  **Penalizaci√≥n por Complejidad:**
    * $\underbrace{\alpha |T|}_{\text{Penalizaci√≥n por Complejidad}}$
    * A√±ade un castigo basado en el tama√±o del √°rbol.
        * $\alpha$: **Par√°metro de penalizaci√≥n**. Un $\alpha$ mayor favorece √°rboles m√°s peque√±os. Si $\alpha = 0$, no hay penalizaci√≥n por tama√±o.
        * $|T|$: **N√∫mero total de hojas** en el √°rbol $T$ (medida de complejidad).

En resumen, se busca el √°rbol $T$ que mejor equilibre el error de ajuste con una penalizaci√≥n por su n√∫mero de hojas, seg√∫n el valor de $\alpha$.

### ¬øC√≥mo se elige el mejor Œ±?

Usando **validaci√≥n cruzada**, que nos ayuda a encontrar el Œ± que logra el mejor equilibrio entre error y simplicidad.

---

## ‚úÖ Ventajas y ‚ùå Desventajas de los √°rboles de decisi√≥n

### ‚úÖ Ventajas

* F√°ciles de entender y explicar.
* Se pueden representar gr√°ficamente.
* Funcionan bien con datos categ√≥ricos sin convertirlos antes (no necesitan variables dummy).
* Se parecen a c√≥mo tomamos decisiones en la vida real.

### ‚ùå Desventajas

* Suelen tener **menos precisi√≥n** que otros m√©todos m√°s sofisticados.
* Son **poco robustos**: un peque√±o cambio en los datos puede generar un √°rbol completamente diferente.

---

# ü§ñ M√©todos de Ensamblaje (Ensemble Methods)

## ¬øQu√© son?

Son t√©cnicas que **combinan muchos modelos** (como √°rboles) para lograr uno mejor, m√°s estable y m√°s preciso.

---

## A. Bagging (Bootstrap Aggregation)

### üß† ¬øQu√© busca resolver?

Un solo √°rbol de decisi√≥n puede ser muy inestable. Si cambias un poco los datos de entrenamiento, el √°rbol puede cambiar mucho (esto se llama **alta varianza**).

### üß∞ ¬øC√≥mo funciona bagging?

1. Tomas tu conjunto original de entrenamiento.
2. Creas **B versiones diferentes** del conjunto, usando **muestreo con reemplazo (bootstrap)**.
3. Entrenas **un √°rbol grande** (sin podar) con cada uno de esos B conjuntos.
4. Para predecir un nuevo dato:

   * Cada √°rbol hace su predicci√≥n.
   * Se **promedian** las predicciones (si es regresi√≥n) o se hace **votaci√≥n mayoritaria** (si es clasificaci√≥n).
---

## üîÑ ¬øPor qu√© hacer esto?

Porque un solo √°rbol puede ser **muy inestable**: si cambias un poco los datos de entrenamiento, el √°rbol puede cambiar mucho. Esto se llama:

### üìà Alta varianza:

El modelo **aprende demasiado** los datos de entrenamiento, incluso el ruido. Esto lo hace muy bueno en ese conjunto... pero malo en datos nuevos.
‚û°Ô∏è Un √°rbol profundo y sin poda es **muy flexible**, pero muy variable.

---

## üß† ¬øY el sesgo?

### üìâ Sesgo:

Es el **error por simplificar demasiado el problema**. Por ejemplo, un modelo muy simple como la regresi√≥n lineal en un problema no lineal tiene **alto sesgo**: no logra capturar la forma real del fen√≥meno.

Un √°rbol muy grande tiene **bajo sesgo**: se adapta muy bien a los datos.

---

## ‚öñÔ∏è ¬øEntonces qu√© hace bagging?

* Toma **muchos modelos con alta varianza** (como √°rboles grandes y no podados).
* Usa **bootstrap** para hacer que cada √°rbol vea algo distinto.
* **Promedia** sus predicciones para **reducir la varianza** sin aumentar demasiado el sesgo.

> ‚ú® Resultado: un modelo m√°s **estable**, **preciso** y **menos sensible** a peque√±as variaciones en los datos.

---

## üß™ Resumen con analog√≠a:

* Un solo √°rbol profundo = un amigo que exagera cuando te da su opini√≥n (alta varianza).
* Bagging = pides la opini√≥n a 100 amigos distintos y sacas un promedio ‚Üí m√°s confiable.

---

## Predicci√≥n Final en Bagging

El modelo de **bagging** (Bootstrap Aggregating) combina varios modelos base para mejorar la precisi√≥n y estabilidad de las predicciones. La forma de combinar las predicciones depende del tipo de problema:

### üéØ Regresi√≥n

Para problemas de regresi√≥n, la predicci√≥n final es el **promedio** de las predicciones de todos los modelos base. Esto ayuda a reducir la varianza y a obtener una predicci√≥n m√°s estable.

La f√≥rmula es:

## F√≥rmula de Bagging (Regresi√≥n)

$$ \hat{f}_{\text{bag}}(x) = \frac{1}{B} \sum_{b=1}^{B} \underbrace{\hat{f}^{*b}(x)}_{\text{Predicci√≥n del √°rbol } b \text{ (entrenado en la muestra bootstrap } b \text{)}} $$

Donde:

* $\hat{f}_{\text{bag}}(x)$: Es la predicci√≥n final del modelo Bagging.
* $B$: Es el n√∫mero total de √°rboles (o modelos) entrenados.
* $\sum_{b=1}^{B}$: Indica la suma de las predicciones de todos los √°rboles, desde el √°rbol 1 hasta el √°rbol $B$.
* $\hat{f}^{*b}(x)$: Es la predicci√≥n del √°rbol n√∫mero $b$.
* $\frac{1}{B}$: Representa la divisi√≥n de la suma por el n√∫mero total de √°rboles para obtener el promedio.
---

### üìä Clasificaci√≥n

Para clasificaci√≥n, la predicci√≥n final se basa en el **voto mayoritario**. Se elige la clase que obtenga m√°s votos de entre los $B$ modelos base, mejorando la estabilidad y precisi√≥n general.

---

## üå± ¬øQu√© es el Error Fuera de Bolsa (OOB)?

Cuando usamos el m√©todo **bagging** (como en Random Forests), no entrenamos un solo modelo. En cambio, entrenamos **muchos √°rboles** usando diferentes subconjuntos de los datos originales.

üß∫ Este proceso se llama **bootstrap**:

* Cada √°rbol se entrena con una **muestra aleatoria con reemplazo**.
* üîÅ Eso significa que algunos datos pueden repetirse, y otros **quedar fuera**.

---

## ‚ùì ¬øQu√© son los datos OOB?

üì¶ Aproximadamente **1 de cada 3 observaciones** no se usan para entrenar un √°rbol.
üåø A estos datos se les llama **Out-of-Bag (OOB)** para ese √°rbol.

---

## üîç ¬øC√≥mo usamos los datos OOB?

Imagina que tenemos una observaci√≥n (dato) llamada `i`.
Para saber qu√© tan bien predice el modelo:

1. üîé Buscamos los √°rboles donde `i` **no fue usada** para entrenar.
2. üìä Usamos esos √°rboles para hacer predicciones sobre `i`.
3. üîÅ Combinamos esas predicciones:

   * Promedio si es **regresi√≥n**.
   * Voto mayoritario si es **clasificaci√≥n**.

---

## üìà ¬øQu√© es el error OOB?

Al comparar las predicciones OOB con los valores reales, calculamos un error promedio:

* üìâ **MSE** (Error Cuadr√°tico Medio) ‚Üí para regresi√≥n.
* ‚ùå **Tasa de error** ‚Üí para clasificaci√≥n.

Este **error OOB** act√∫a como una **estimaci√≥n del error real del modelo**, sin necesidad de un conjunto de prueba aparte.

> ‚úÖ Es como tener una evaluaci√≥n autom√°tica y confiable del modelo, usando solo los datos que **cada √°rbol no vio**.

---

## üå≤ B. Random Forest

**¬øPor qu√© es mejor que Bagging?**
Random Forest mejora el m√©todo de √°rboles bagged al **reducir la correlaci√≥n entre los √°rboles**, lo que hace que el promedio final sea m√°s **estable y preciso**.

---

### ‚öôÔ∏è ¬øC√≥mo funciona?

Igual que en **bagging**, se construyen muchos √°rboles (por ejemplo, B √°rboles) usando muestras aleatorias del conjunto de entrenamiento.

> üìå **Nota**: Estas muestras son *bootstrap*, es decir, se seleccionan **al azar con reemplazo**. Algunos datos se repiten y otros quedan fuera.

---

### üîë Diferencia clave

En **cada divisi√≥n** dentro de un √°rbol:

* Solo se considera un **subconjunto aleatorio de m predictores**, no todos los p disponibles.
* La divisi√≥n solo puede hacerse usando **uno de esos m**.

> Ejemplo: si hay 100 predictores, el algoritmo puede usar solo 10 para decidir una divisi√≥n.
> En clasificaci√≥n, t√≠picamente m ‚âà ‚àöp.
> En regresi√≥n, m ‚âà p/3.

---

### ü§î ¬øPor qu√© esto funciona?

En **bagging**, si hay un predictor muy fuerte, casi todos los √°rboles lo usar√°n en la parte superior, haciendo que los √°rboles sean muy **similares entre s√≠**.

* üîÅ Promediar √°rboles muy parecidos **no reduce tanto la variaci√≥n** del modelo final.

En cambio, Random Forest introduce **diversidad entre los √°rboles**:

* Muchas divisiones **ni siquiera ver√°n al predictor dominante**.
* Esto da oportunidad a otros predictores y **descorrelaciona los √°rboles**.
* üìâ Al promediar √°rboles menos correlacionados, se reduce m√°s la varianza, obteniendo un modelo m√°s **robusto y confiable**.

---

> ‚úÖ **Si se usa m = p**, entonces Random Forest se comporta igual que **Bagging**.

---

## üöÄ C. Boosting

### üåü Idea principal

Boosting construye √°rboles de decisi√≥n **de forma secuencial**.
Cada nuevo √°rbol **aprende de los errores** cometidos por los √°rboles anteriores.

A diferencia de bagging y random forest:

* ‚ùå No usa muestreo bootstrap.
* ‚úÖ Cada √°rbol se ajusta a una **versi√≥n modificada del conjunto de entrenamiento**, donde se da m√°s importancia a los errores previos.

---

### ‚öôÔ∏è ¬øC√≥mo funciona? (versi√≥n para regresi√≥n)

1. **Inicializar el modelo** con
   $$ \hat{f}(x) = 0 $$
   y los residuos: $r_i$ = $y_i$ (es decir, el error de cada observaci√≥n).

2. Para b = 1, 2, ..., B (cantidad de √°rboles), repetir:

   a. **Ajustar un √°rbol** fÃÇ\_b con profundidad limitada (por ejemplo, d divisiones)
   usando las caracter√≠sticas X y los residuos r como respuesta.

   b. **Actualizar el modelo**:
   $$ \hat{f}(x) \leftarrow \underbrace{\hat{f}(x)}_{\text{Predicci√≥n acumulada anterior}} + \underbrace{\lambda \hat{f}^b(x)}_{\text{Peque√±a correcci√≥n del nuevo √°rbol } b} $$

   (se suma una versi√≥n "encogida" del √°rbol reci√©n creado).

   c. **Actualizar los residuos**:
   $$ r_i \leftarrow \underbrace{r_i}_{\text{Error anterior}} - \underbrace{\lambda \hat{f}^b(x_i)}_{\text{Parte del error corregida por el nuevo √°rbol } b} $$

3. El modelo final es la suma de todos los √°rboles:
   $$ \hat{f}(x) = \sum_{b=1}^{B} \underbrace{\lambda \hat{f}^b(x)}_{\text{Contribuci√≥n del √°rbol } b \text{ (ajustada por } \lambda \text{)}} $$

---

### üõ†Ô∏è Par√°metros clave

* **N√∫mero de √°rboles (B):**
  A diferencia de random forest, aqu√≠ usar demasiados √°rboles puede causar **sobreajuste**, aunque lo hace gradualmente.
  üîç Se recomienda usar **validaci√≥n cruzada** para elegir B.

* **Tasa de aprendizaje (Œª):**
  Tambi√©n llamado *shrinkage*.
  Es un n√∫mero peque√±o (ej. 0.01 o 0.001) que **controla cu√°nto aporta cada nuevo √°rbol**.
  Cuanto m√°s peque√±o es Œª, **m√°s lento y cuidadoso es el aprendizaje** ‚Äî pero necesitar√°s m√°s √°rboles.

* **N√∫mero de divisiones por √°rbol (d):**
  Esto determina la **complejidad de cada √°rbol individual**.

  * d = 1 crea "stumps" (√°rboles muy simples).
  * Valores mayores permiten capturar interacciones m√°s complejas entre variables.

---

## üîÆ D. Bayesian Additive Regression Trees (BART)

### üåü Idea principal

BART es un m√©todo de ensamble que combina dos enfoques:

* La **aleatoriedad** de bagging o random forest.
* El **aprendizaje secuencial** de boosting.

Cada √°rbol intenta capturar la se√±al que **los dem√°s √°rboles a√∫n no explican**.

---

### ‚öôÔ∏è ¬øC√≥mo funciona? (para regresi√≥n)

1. Inicialmente, se crean K √°rboles simples.
   Por ejemplo, cada √°rbol empieza prediciendo el promedio de las respuestas divididas por K.

$$ \hat{f}_k^1(x) = \frac{1}{nK} \sum_{i=1}^{n} y_i $$

2. Para cada iteraci√≥n b = 2, ..., B:

   a. Para cada √°rbol k = 1, ..., K:

   * Se calcula un residuo parcial para cada observaci√≥n i:
     r·µ¢ = y·µ¢ ‚àí suma de predicciones de *todos los otros* √°rboles en la iteraci√≥n actual.

   * En lugar de crear un √°rbol nuevo desde cero, BART **modifica ligeramente** (perturba) el √°rbol k de la iteraci√≥n anterior:

     * Cambia ramas (a√±ade o poda).
     * Ajusta predicciones en nodos terminales.

$$ r_i = \underbrace{y_i}_{\text{Valor real}} - \underbrace{\left( \sum_{k' < k} \hat{f}_{k'}^b(x_i) + \sum_{k' > k} \hat{f}_{k'}^{b-1}(x_i) \right)}_{\text{Predicci√≥n de los OTROS K-1 √°rboles}} $$

   b. Se suma la predicci√≥n de los K √°rboles perturbados para obtener el modelo en la iteraci√≥n b.
   

   $$ \hat{f}^b(x) = \sum_{k=1}^{K} \hat{f}_k^b(x) $$

3. La predicci√≥n final es el promedio de los modelos desde la iteraci√≥n L+1 hasta B (se descarta un per√≠odo inicial llamado "burn-in" para estabilizar el modelo).

$$ \hat{f}(x) = \frac{1}{B-L} \sum_{b=L+1}^{B} \underbrace{\hat{f}^b(x)}_{\text{Predicci√≥n del modelo en la iteraci√≥n } b} $$

---

### üîë Aspectos clave

* La **perturbaci√≥n suave** evita que el modelo se sobreajuste demasiado r√°pido.
* Los √°rboles individuales suelen ser **muy peque√±os**.
* Es un enfoque **Bayesiano**, usando t√©cnicas avanzadas de Monte Carlo (MCMC).

---

### üìä √Årboles vs. Modelos Lineales

* Los **modelos lineales** asumen que la relaci√≥n entre predictores y respuesta es una combinaci√≥n lineal:
  $$ f(X) = \underbrace{\beta_0}_{\text{Intercepto (valor base)}} + \sum_{j=1}^{p} \underbrace{X_j \beta_j}_{\text{Contribuci√≥n de la variable } X_j} $$

  - **Œ≤‚ÇÄ**: Es el valor predicho cuando todas las $X_j$ son cero.  
- $X_j$: Es el valor de la variable predictora $j$.  
- $Œ≤_j$: Es el coeficiente (peso) que indica cu√°nto cambia $f(X)$ si $X_j$ aumenta en una unidad.  
- $p$: N√∫mero total de variables predictoras.


* Los **modelos de √°rbol** predicen valores constantes en regiones espec√≠ficas del espacio de predictores:
  $$ f(X) = \sum_{m=1}^{M} \underbrace{c_m}_{\text{Valor predicho en la regi√≥n } R_m} \cdot \underbrace{1(X \in R_m)}_{\text{Funci√≥n indicadora}} $$
  (donde c‚Çò es la predicci√≥n para la regi√≥n R‚Çò)

---

### ü§î ¬øCu√°l es mejor?

* Si la relaci√≥n entre variables es **lineal o casi lineal**, la regresi√≥n lineal suele funcionar mejor.
* Si la relaci√≥n es **no lineal y compleja**, los √°rboles (como BART) pueden capturar patrones que los modelos lineales no ven.

---
## üìä Cuadro Comparativo

| Caracter√≠stica              | Bagging                         | Random Forest                       | Boosting                         | BART                                  |
|----------------------------|--------------------------------|-----------------------------------|---------------------------------|---------------------------------------|
| **Idea principal**          | Construir varios √°rboles independientes con muestras bootstrap | Similar a bagging, pero cada divisi√≥n usa solo un subconjunto aleatorio de predictores para reducir correlaci√≥n entre √°rboles | Construcci√≥n secuencial: cada √°rbol corrige errores de los anteriores | Ensamble Bayesiano: √°rboles perturbados secuencialmente para capturar se√±ales no explicadas |
| **Muestreo**               | Bootstrap (muestras con reemplazo) | Bootstrap + selecci√≥n aleatoria de predictores en cada divisi√≥n | Sin bootstrap, se usa todo el dataset pero ajustado con residuos | Sin bootstrap, modifica √°rboles existentes para mejorar ajuste |
| **Dependencia entre √°rboles** | Independientes                 | Menos correlacionados (por selecci√≥n de predictores) | Altamente dependientes (secuenciales) | Altamente dependientes con perturbaciones suaves |
| **Predicci√≥n final**        | Promedio o voto mayoritario     | Promedio o voto mayoritario         | Suma ponderada de √°rboles con tasa de aprendizaje (shrinkage) | Promedio de √°rboles tras periodo de burn-in |
| **Sobreajuste**             | Poco propenso                   | Menos propenso que bagging          | Puede sobreajustar si hay demasiados √°rboles o alta tasa de aprendizaje | Dise√±ado para evitar sobreajuste con perturbaciones y enfoque Bayesiano |
| **Par√°metros clave**        | N√∫mero de √°rboles B             | N√∫mero de √°rboles B, n√∫mero m de predictores para divisi√≥n | B, tasa de aprendizaje Œª, profundidad de √°rboles d | N√∫mero de √°rboles K, n√∫mero de iteraciones B, burn-in L |
| **Complejidad del modelo**  | √Årboles completos               | √Årboles completos, pero menos correlacionados | √Årboles poco profundos (stumps o m√°s) y secuenciales | √Årboles peque√±os perturbados iterativamente |
| **Ventajas**                | F√°cil de entender y paralelo   | Mejora sobre bagging al reducir correlaci√≥n | Mejor rendimiento en muchas tareas, captura relaciones complejas | Modelo flexible que combina aleatoriedad y secuencialidad, con protecci√≥n contra sobreajuste |
| **Cu√°ndo usarlo**           | Datos con ruido moderado, modelos r√°pidos | Cuando hay muchos predictores y se busca robustez | Cuando se quiere m√°xima precisi√≥n y se dispone de tiempo para entrenamiento | Para patrones no lineales complejos y necesidad de inferencia Bayesiana |


# Implementacion:
empezaos importando andomForestClassifier a load_breast_cancer, por que hacemos esto pues queremos crear un modelo el cual aprenda a distinguir entre clases definidas en el dataset(benigno o maligno) basandose en caracteriticas de las celulas mamarias.

1. predecir la clase, para nuevos casoso que no hayammos visto antes
2. y queremos evaluar que tan bien funciona nuestro modelo 

cargamos todos los datos neceserarios y como buena practica imprimos las formas de los datos
ahora tenemos que emepezar a entrena al mdelo osea la damos una instancia, llamamos al metodo de ensablaje
```python
random_forest_model = RandomForestClassifier()
```

---

## Par√°metros Principales de `RandomForestClassifier`

A continuaci√≥n, se describen los par√°metros clave para configurar un modelo de **Random Forest** con `RandomForestClassifier` de forma sencilla:

| Par√°metro               | Tipo                   | Valor por defecto | Descripci√≥n                                                                                                                                           |
| ----------------------- | ---------------------- | ----------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- |
| **n\_estimators**       | int                    | 100               | N√∫mero de √°rboles que forman el bosque.                                                                                                               |
| **criterion**           | str                    | 'gini'            | Funci√≥n para medir la calidad de una divisi√≥n: puede ser `'gini'` o `'entropy'`.                                                                      |
| **max\_depth**          | int o None             | None              | Profundidad m√°xima de cada √°rbol. Si es `None`, los √°rboles crecen hasta que las hojas sean puras o muy peque√±as.                                     |
| **min\_samples\_split** | int o float            | 2                 | M√≠nimo n√∫mero de muestras requeridas para dividir un nodo interno.                                                                                    |
| **min\_samples\_leaf**  | int o float            | 1                 | M√≠nimo n√∫mero de muestras que debe tener una hoja.                                                                                                    |
| **max\_features**       | int, float, str o None | 'auto'            | N√∫mero de caracter√≠sticas a considerar para encontrar la mejor divisi√≥n. Puede ser un n√∫mero, porcentaje o valores como `'auto'`, `'sqrt'`, `'log2'`. |
| **bootstrap**           | bool                   | True              | Indica si se usa muestreo bootstrap para construir los √°rboles.                                                                                       |
| **random\_state**       | int o None             | None              | Semilla para la generaci√≥n de n√∫meros aleatorios, para que los resultados sean reproducibles.                                                         |
| **n\_jobs**             | int o None             | None              | N√∫mero de procesos paralelos para entrenamiento. `-1` usa todos los CPUs disponibles.                                                                 |

---

## üå≤ Implementaci√≥n de RandomForestClassifier en el Modelo

En esta secci√≥n se implementa el modelo **Random Forest** para clasificaci√≥n binaria utilizando el conjunto de datos `load_breast_cancer` de `sklearn.datasets`. Este dataset es ampliamente utilizado en problemas m√©dicos de clasificaci√≥n, como la detecci√≥n de tumores malignos.

### üõ†Ô∏è Proceso General

1. **Carga de datos**: Se importa `load_breast_cancer` y se asignan nombres a las caracter√≠sticas para mantener un an√°lisis estructurado.
2. **Separaci√≥n de datos**: Se utiliza `train_test_split` para dividir el conjunto en entrenamiento y prueba, lo que asegura que la evaluaci√≥n del modelo sea v√°lida y no est√© sesgada por los datos usados para entrenar.
3. **Inicializaci√≥n del modelo**: Se entrena un clasificador `RandomForestClassifier` con los siguientes hiperpar√°metros:

```python
f_model = RandomForestClassifier(n_estimators=50, max_depth=3, random_state=42)
```

4. **Selecci√≥n de hiperpar√°metros**: Los valores se seleccionaron tras varias pruebas comparativas para buscar el equilibrio ideal entre **precisi√≥n**, **recall** y **sobreajuste**.
5. **Evaluaci√≥n sistem√°tica**: Se implement√≥ un bucle para iterar sobre distintos valores de `max_depth`, lo que permiti√≥ encontrar la profundidad adecuada que **evite el sobreajuste** sin subajustar el modelo.

---

### üìã Tabla Resumen: Comparaci√≥n por Profundidad (`max_depth`)

| max\_depth | Accuracy Train | Accuracy Test | Observaciones                   |
| ---------- | -------------- | ------------- | ------------------------------- |
| 1          | 0.93           | 0.92          | Subajuste (modelo muy simple)   |
| 2          | 0.95           | 0.94          | Buen equilibrio inicial         |
| 3          | 0.98           | 0.96          | Mejor resultado sin sobreajuste |
| 4          | 0.99           | 0.95          | Ligero sobreajuste              |
| 5+         | 1.00           | 0.94          | Sobreajuste claro               |

> üîç **Conclusi√≥n**: La profundidad √≥ptima es **3**, ya que maximiza el rendimiento sobre el conjunto de prueba sin llegar a memorizar los datos de entrenamiento.

---

| max_depth | Conjunto | Precisi√≥n (0) | Precisi√≥n (1) | Recall (0) | Recall (1) | F1-score (0) | F1-score (1) | Accuracy | Macro Avg F1 | Weighted Avg F1 |
|-----------|----------|---------------|---------------|------------|------------|--------------|--------------|----------|--------------|-----------------|
| 3         | Test     | 0.98          | 0.96          | 0.93       | 0.99       | 0.95         | 0.97         | 0.96     | 0.96         | 0.96            |
|           | Train    | 1.00          | 0.97          | 0.95       | 1.00       | 0.98         | 0.99         | 0.98     | 0.98         | 0.98            |
| 5         | Test     | 0.98          | 0.96          | 0.93       | 0.99       | 0.95         | 0.97         | 0.96     | 0.96         | 0.96            |
|           | Train    | 1.00          | 0.99          | 0.98       | 1.00       | 0.99         | 0.99         | 0.99     | 0.99         | 0.99            |
| 7         | Test     | 0.98          | 0.96          | 0.93       | 0.99       | 0.95         | 0.97         | 0.96     | 0.96         | 0.96            |
|           | Train    | 1.00          | 0.99          | 0.99       | 1.00       | 0.99         | 1.00         | 1.00     | 1.00         | 1.00            |
| 10        | Test     | 0.98          | 0.96          | 0.93       | 0.99       | 0.95         | 0.97         | 0.96     | 0.96         | 0.96            |
|           | Train    | 1.00          | 1.00          | 1.00       | 1.00       | 1.00         | 1.00         | 1.00     | 1.00         | 1.00            |
| 15        | Test     | 0.98          | 0.96          | 0.93       | 0.99       | 0.95         | 0.97         | 0.96     | 0.96         | 0.96            |
|           | Train    | 1.00          | 1.00          | 1.00       | 1.00       | 1.00         | 1.00         | 1.00     | 1.00         | 1.00            |

### Observaciones:
1. **Rendimiento en Test**:  
   - Todos los modelos tienen el mismo rendimiento en el conjunto de prueba, con un **accuracy del 96%** y m√©tricas consistentes (F1-score: 0.95 para clase 0, 0.97 para clase 1).  
   - No hay variaci√≥n con el aumento de `max_depth`, lo que sugiere que el modelo generaliza bien incluso con poca profundidad.

2. **Rendimiento en Train**:  
   - A medida que aumenta `max_depth`, el modelo se ajusta mejor a los datos de entrenamiento, alcanzando un **accuracy del 100%** con `max_depth ‚â• 7`.  
   - Esto indica posible **sobreajuste** en profundidades mayores, aunque no afecta el rendimiento en test.

3. **Conclusi√≥n**:  
   - `max_depth = 3` es suficiente para este problema, ya que no hay mejora en test con mayor profundidad.  
   - El modelo es robusto y estable en generalizaci√≥n.

---

## üìà Resumen de M√©tricas de Evaluaci√≥n en Clasificaci√≥n Binaria

Las m√©tricas de evaluaci√≥n permiten analizar el rendimiento de los modelos, especialmente en problemas donde hay clases desbalanceadas o consecuencias m√©dicas importantes.

| **M√©trica**   | **Se enfoca en...**                         | **Qu√© busca evitar**        |
| ------------- | ------------------------------------------- | --------------------------- |
| **Precision** | Predicciones positivas que fueron correctas | Falsos Positivos (FP)       |
| **Recall**    | Casos positivos correctamente detectados    | Falsos Negativos (FN)       |
| **F1-score**  | Balance entre Precision y Recall            | Desequilibrio entre FP y FN |

---

## ü§ñ Comparaci√≥n de Modelos de Clasificaci√≥n

Este an√°lisis compara tres modelos aplicados a un problema m√©dico de clasificaci√≥n binaria (por ejemplo, diagn√≥stico de tumores malignos), evaluados con m√©tricas clave para cada clase.

### üìä Comparaci√≥n de M√©tricas entre Modelos

| **M√©trica**             | **Random Forest**<br>(n\_estimators=50, max\_depth=3) | **Regresi√≥n Log√≠stica** | **SVC**<br>(kernel='linear', C=0.1) |
| ----------------------- | ----------------------------------------------------- | ----------------------- | ----------------------------------- |
| **Accuracy**            | 0.96                                                  | 0.96                    | 0.96                                |
| **Precision (Clase 0)** | 0.98                                                  | 0.95                    | 0.98                                |
| **Recall (Clase 0)**    | 0.93                                                  | 0.95                    | 0.93                                |
| **F1-score (Clase 0)**  | 0.95                                                  | 0.95                    | 0.95                                |
| **Precision (Clase 1)** | 0.96                                                  | **0.97**                | 0.96                                |
| **Recall (Clase 1)**    | **0.99**                                              | 0.97                    | **0.99**                            |
| **F1-score (Clase 1)**  | 0.97                                                  | 0.97                    | 0.97                                |

---

### üéØ Interpretaci√≥n Cl√≠nica

#### ‚úÖ Recall (Sensibilidad) para la Clase 1 ("Maligno"):

* **Random Forest y SVC** alcanzan un **Recall de 0.99**, lo cual significa que identifican casi todos los tumores malignos (minimizan los **Falsos Negativos**, crucial en medicina).
* **Regresi√≥n Log√≠stica** obtiene un Recall de 0.97, que sigue siendo muy bueno pero ligeramente menor.

#### üìå Precision para la Clase 1 ("Maligno"):

* **Regresi√≥n Log√≠stica** tiene la mayor precisi√≥n (**0.97**), lo que significa que cuando predice "maligno", tiene mayor probabilidad de acertar (minimiza **Falsos Positivos**). En medicina, esto evita diagn√≥sticos err√≥neos que podr√≠an generar ansiedad o tratamientos innecesarios.

#### ‚öñÔ∏è F1-score para la Clase 1:

* Todos los modelos obtienen un excelente **F1-score de 0.97**, lo que indica un **equilibrio s√≥lido** entre precisi√≥n y sensibilidad.

#### üß† Accuracy Global:

* Los tres modelos alcanzan una **accuracy del 96%**, pero esta m√©trica por s√≠ sola **no es suficiente** en problemas cl√≠nicos, donde los costos de errores son diferentes para cada clase.

---

## üß™ An√°lisis de Sobreajuste

| Modelo                  | Accuracy Entrenamiento | Accuracy Test | Observaci√≥n                        |
| ----------------------- | ---------------------- | ------------- | ---------------------------------- |
| **Random Forest**       | 0.98                   | 0.96          | Leve sobreajuste                   |
| **Regresi√≥n Log√≠stica** | 0.93                   | 0.96          | Sin sobreajuste, posible subajuste |
| **SVC**                 | 0.96                   | 0.96          | Excelente generalizaci√≥n           |

---

## ü©∫ Consideraciones Finales

En un escenario m√©dico como la detecci√≥n de c√°ncer:

* üîé **Minimizar Falsos Negativos (FN)** es **prioritario**, para no dejar casos malignos sin tratamiento.
* üßò **Minimizar Falsos Positivos (FP)** tambi√©n es importante, para evitar alarmas innecesarias o procedimientos invasivos.

Dado que los tres modelos tienen **F1-score y Accuracy similares**, la elecci√≥n debe centrarse en:

* ¬øQu√© tipo de error es m√°s tolerable en la aplicaci√≥n real?
* ¬øSe prefiere detectar todos los casos malignos aunque se tengan algunos falsos positivos? ‚Üí **Mayor Recall (RF y SVC)**
* ¬øSe prefiere acertar cada vez que se predice maligno, incluso si se escapan algunos casos? ‚Üí **Mayor Precisi√≥n (RL)**

---
# üöÄ ¬øQu√© es Gradient Boosting Machines (GBM)?

## üå≥ ¬øEn qu√© se parece y en qu√© se diferencia de Random Forest (RF)?

### üé≤ ¬øQu√© es Bootstrap?

- Imagina que tienes una bolsa con muchas pelotas (datos).
- Sacas pelotas al azar y las vuelves a poner en la bolsa (con reemplazo).
- As√≠ puedes sacar muchas bolsitas con pelotas diferentes para entrenar varios √°rboles.

### üå≤ Random Forest (Bosque Aleatorio)

- Crea muchos √°rboles de decisiones.
- Cada √°rbol aprende con una bolsita diferente de pelotas.
- Luego, todos los √°rboles votan para dar la respuesta final.
- Esto ayuda a que el modelo no se equivoque mucho porque usa muchas opiniones.

---

## ‚ö° ¬øQu√© es Boosting?

- Aqu√≠ los √°rboles se construyen uno despu√©s del otro, en fila.
- Cada √°rbol nuevo aprende de los errores que cometi√≥ el √°rbol anterior.
- As√≠, poco a poco, el modelo mejora y comete menos errores.

---

## ‚ùå Diferencias importantes

| Random Forest                    | Boosting                                |
|---------------------------------|----------------------------------------|
| √Årboles independientes          | √Årboles que aprenden uno del otro      |
| Usa muchas muestras con reemplazo | No usa muestras con reemplazo igual    |
| Votan para decidir la respuesta  | Corrigen errores uno a uno              |

---

## üß† ¬øC√≥mo aprende Boosting de los errores?

- El primer √°rbol se equivoca en algunos datos.
- El segundo √°rbol presta m√°s atenci√≥n a esos errores.
- El tercero hace lo mismo, corrigiendo lo que los anteriores fallaron.
- As√≠, mejora paso a paso.

---

## üéõÔ∏è Palabras clave que ayudan a controlar el modelo

| Nombre           | Qu√© hace                      | Por qu√© importa                       |
|------------------|------------------------------|-------------------------------------|
| **N√∫mero de √°rboles** (`n_estimators`) | Cu√°ntos √°rboles habr√°       | Muchos √°rboles pueden hacer que el modelo se confunda con datos raros (sobreajuste) |
| **Profundidad** (`max_depth`)         | Qu√© tan complejo es cada √°rbol | √Årboles simples ayudan a que el modelo no aprenda cosas equivocadas |
| **Velocidad de aprendizaje** (`learning_rate`) | Qu√© tan fuerte corrige cada √°rbol | Si corrige lento, necesita m√°s √°rboles; si corrige r√°pido, puede confundirse |

---

## üé® Una forma f√°cil de imaginarlo

- **Profundidad (max_depth)**: es como el tama√±o del pincel para pintar ‚Äî pinceles grandes hacen trazos simples, pinceles peque√±os hacen detalles.
- **Velocidad de aprendizaje (learning_rate)**: es qu√© tan fuerte pintas cada vez ‚Äî un golpe fuerte cambia mucho, un golpecito suave cambia poco.

---

## ‚öñÔ∏è ¬øC√≥mo trabajan juntos la velocidad y la cantidad de √°rboles?

- Si pintas despacio (learning_rate bajo), necesitas pintar muchas veces (m√°s √°rboles).
- Si pintas r√°pido (learning_rate alto), necesitas menos veces, pero puedes cometer errores.

---

## üìå Resumen r√°pido para recordar

- Random Forest usa muchas "opiniones" diferentes de √°rboles que no se comunican.
- Boosting construye √°rboles en fila, donde cada uno corrige errores del anterior.
- Hay tres botones para ajustar:  
  1. Cu√°ntos √°rboles usar  
  2. Qu√© tan complejos son los √°rboles  
  3. Qu√© tan r√°pido aprenden los √°rboles  


# üíñ ¬øQu√© librer√≠a usar para el dataset de c√°ncer de mama? (sklearn.datasets - breast_cancer)

---

## ‚öîÔ∏è **XGBoost vs LightGBM** (Resumen r√°pido y sencillo)

| Cosa que importa          | **XGBoost**                             | **LightGBM**                                  |
|--------------------------|---------------------------------------|----------------------------------------------|
| üöÄ Velocidad              | R√°pido                                | **M√°s r√°pido** en datos muy grandes          |
| üéØ Precisi√≥n              | Muy buena                            | Igual o mejor a veces                         |
| üß© Datos con categor√≠as   | Tienes que preparar los datos t√∫ mismo | **Lo hace solo, es m√°s f√°cil**                |
| üå≥ C√≥mo crece el √°rbol    | Nivel por nivel (m√°s ordenado)         | Hoja por hoja (m√°s agresivo)                  |
| üóÇ Tama√±o de los datos    | Bueno para datos medianos o peque√±os   | Mejor para datos muy grandes                   |
| üß† Memoria que usa        | Usa m√°s memoria                         | Usa menos memoria (m√°s eficiente)             |
| üõ° Control de errores      | Bueno para evitar confusi√≥n (overfitting) | Puede confundirse m√°s si no lo cuidas          |
| ‚öôÔ∏è Trabaja en paralelo    | Muy bien                              | **Mejor a√∫n, m√°s r√°pido**                      |
| üë• Comunidad y ayuda      | Mucha informaci√≥n y ayuda disponible  | Menos gente pero creciendo r√°pido              |

---

## üéØ ¬øCu√°l elegir?

- **Usa LightGBM si:**
  - Tienes muchos datos grandes.
  - Tienes muchas categor√≠as (tipos) de cosas.
  - Quieres que sea r√°pido y no use mucha memoria.
  - Sabes que hay que ajustar bien para que no se confunda.

- **Usa XGBoost si:**
  - Quieres algo m√°s estable y seguro.
  - Te gusta que sea f√°cil de usar y entender.
  - Tus datos no son tan grandes y la velocidad no es problema.

---

## ‚úÖ ¬øY para el dataset de c√°ncer de mama?

- **XGBoost** es la mejor opci√≥n por ser m√°s estable y f√°cil.
- LightGBM tambi√©n funciona, pero no se notan tanto sus ventajas porque el dataset es peque√±o.

---

## üõ† C√≥mo usar XGBoost con este dataset

1. Carga los datos de c√°ncer de mama desde sklearn.
2. Divide los datos en dos grupos: entrenamiento (80%) y prueba (20%).
3. Puedes usar los datos normales o escalados (m√°s parejos), aunque con XGBoost no es obligatorio.
4. Crea el modelo con estas opciones para evitar problemas:
   - `eval_metric='logloss'` (para que el modelo se eval√∫e bien).
   - `random_state=42` (para que los resultados sean iguales siempre que repitas).

---

## üìä ¬øC√≥mo se comparan los modelos?


| M√©trica             | Random Forest (RF) <br> (n\_est=50, max\_d=3) | Regresi√≥n Log√≠stica (RL) | SVC <br> (kernel='linear', C=0.1) | XGBoost (XGB) <br> (n\_est=50, lr=0.01, max\_d=3) |
| ------------------- | --------------------------------------------- | ------------------------ | --------------------------------- | ------------------------------------------------- |
| Accuracy            | 0.9649                                        | 0.9649                   | 0.9649                            | 0.9649                                            |
| Precision (clase 0) | 0.98                                          | 0.95                     | 0.98                              | 0.98                                              |
| Recall (clase 0)    | 0.93                                          | 0.95                     | 0.93                              | 0.93                                              |
| F1-score (clase 0)  | 0.95                                          | 0.95                     | 0.95                              | 0.95                                              |
| Precision (clase 1) | 0.96                                          | 0.97                     | 0.96                              | 0.96                                              |
| Recall (clase 1)    | 0.99                                          | 0.97                     | 0.99                              | 0.99                                              |
| F1-score (clase 1)  | 0.97                                          | 0.97                     | 0.97                              | 0.97                                              |
| Train Accuracy      | 0.9802                                        | 0.9297                   | 0.9626                            | 0.9780                                            |
| Overfitting (Gap)   | \~1.53%                                       | (-3.52%)                 | \~0.23%                           | \~1.31%                                           |

---

## üîç ¬øQu√© significa todo esto?

- Todos los modelos aciertan casi igual (96.49%).
- Para detectar el c√°ncer (clase 1), casi todos son igual de buenos.
- SVC es el que menos se confunde (menos sobreajuste).
- XGBoost es casi tan bueno y tambi√©n muy estable.
- Regresi√≥n Log√≠stica a veces puede ser demasiado simple para estos datos.


Perfecto, aqu√≠ tienes una versi√≥n clara, organizada y **lista para tu README.md**, siguiendo las tres sugerencias opcionales que mencionaste, redactadas con un lenguaje t√©cnico claro pero accesible y duradero:

---

## üîç Documentaci√≥n de Experimentos

### üå≤ Random Forest (RF)

Durante la experimentaci√≥n con Random Forest, se probaron diferentes combinaciones de hiperpar√°metros, especialmente **n\_estimators** (cantidad de √°rboles) y **max\_depth** (profundidad m√°xima de cada √°rbol).

Una de las pruebas clave fue evaluar c√≥mo cambiaba el rendimiento con distintas profundidades. A continuaci√≥n se resume una parte relevante de esos experimentos:

| max\_depth | Accuracy Entrenamiento | Accuracy Prueba |
| ---------- | ---------------------- | --------------- |
| 1          | 0.9297                 | 0.9298          |
| 3          | 0.9802                 | 0.9649 ‚úÖ        |
| 5          | 0.9978                 | 0.9561          |
| 10         | 1.0000                 | 0.9561          |

Se observa que **max\_depth=3** ofrece el mejor balance entre rendimiento y sobreajuste.
Combinado con **n\_estimators=50**, se obtuvo una accuracy de prueba de 0.9649 con solo \~1.5% de sobreajuste.
üëâ **Estos son los valores usados en la tabla comparativa final.**

---

### ‚öôÔ∏è XGBoost

Para XGBoost, se realiz√≥ una b√∫squeda de combinaciones entre estos hiperpar√°metros:

* `n_estimators = [10, 50, 100]`
* `max_depth = [1, 3, 5]`
* `learning_rate = [0.01, 0.1, 0.3]`

Utilizando `itertools.product`, se probaron todas las combinaciones posibles.
El resultado m√°s equilibrado entre rendimiento, tiempo de entrenamiento y control de sobreajuste fue:

* `n_estimators = 50`
* `max_depth = 3`
* `learning_rate = 0.01`

Esta combinaci√≥n logr√≥:

* **Accuracy en prueba:** 0.9649
* **Accuracy en entrenamiento:** 0.9780
* **Overfitting (diferencia):** \~1.31%

üëâ Por eso estos valores tambi√©n fueron seleccionados para la tabla comparativa final.

---
# Documentaci√≥n de Experimentos y Conclusiones

## üîç Documentaci√≥n de Experimentos

### üå≤ Random Forest (RF)

Durante la experimentaci√≥n con Random Forest, se probaron diferentes combinaciones de hiperpar√°metros, especialmente **n_estimators** (cantidad de √°rboles) y **max_depth** (profundidad m√°xima de cada √°rbol).

Una de las pruebas clave fue evaluar c√≥mo cambiaba el rendimiento con distintas profundidades. A continuaci√≥n se resume una parte relevante de esos experimentos:

| max_depth | Accuracy Entrenamiento | Accuracy Prueba |
|-----------|------------------------|-----------------|
| 1         | 0.9297                 | 0.9298          |
| 3         | 0.9802                 | 0.9649 ‚úÖ        |
| 5         | 0.9978                 | 0.9561          |
| 10        | 1.0000                 | 0.9561          |

Se observa que **max_depth=3** ofrece el mejor balance entre rendimiento y sobreajuste.  
Combinado con **n_estimators=50**, se obtuvo una accuracy de prueba de 0.9649 con solo ~1.5% de sobreajuste.  
üëâ **Estos son los valores usados en la tabla comparativa final.**

---

### ‚öôÔ∏è XGBoost

Para XGBoost, se realiz√≥ una b√∫squeda de combinaciones entre estos hiperpar√°metros:

`n_estimators_list = [50, 100, 200]`
`max_depth_list = [2, 3, 4, 5, 6, 7]`
`learning_rate_list = [0.01, 0.05, 0.1]`

Utilizando `itertools.product`, se probaron todas las combinaciones posibles.  
El resultado m√°s equilibrado entre rendimiento, tiempo de entrenamiento y control de sobreajuste fue:

- `n_estimators = 50`
- `max_depth = 3`
- `learning_rate = 0.01`

Esta combinaci√≥n logr√≥:

- **Accuracy en prueba:** 0.9649
- **Accuracy en entrenamiento:** 0.9780
- **Overfitting (diferencia):** ~1.31%

üëâ Por eso estos valores tambi√©n fueron seleccionados para la tabla comparativa final.

---

## ‚úÖ Conclusi√≥n Final

Todos los modelos principales (SVC, Random Forest, XGBoost y Regresi√≥n Log√≠stica) alcanzaron una precisi√≥n muy alta (~96.49%) en el conjunto de prueba, lo cual indica que el dataset es altamente separable.

Sin embargo:

- üõ° **SVC (kernel='linear', C=0.1)** se destaca por tener **el menor nivel de sobreajuste (~0.23%)**, lo que lo convierte en el modelo m√°s **robusto y confiable** para este problema espec√≠fico.
- üå≤ Random Forest y XGBoost tambi√©n mostraron excelente rendimiento, pero con un poco m√°s de diferencia entre entrenamiento y prueba.
- üìâ Regresi√≥n Log√≠stica tuvo un rendimiento similar, aunque mostr√≥ una se√±al de subajuste (accuracy de prueba mayor que la de entrenamiento).

üëâ **Recomendaci√≥n final:**  
**SVC (con kernel lineal y C=0.1)** es la mejor opci√≥n para este problema por su excelente equilibrio entre precisi√≥n y generalizaci√≥n.

---

