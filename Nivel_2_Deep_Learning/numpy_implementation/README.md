# üß† Red Neuronal con NumPy: 

> ‚ÄúEntender una red neuronal es descomponer la magia en matem√°ticas y funciones simples.‚Äù

---
  ### Resumen Clave üìù
  Una red neuronal artificial transforma entradas mediante combinaciones lineales y funciones no lineales llamadas activaciones para aprender patrones complejos. La propagaci√≥n hacia adelante calcula salidas, mientras que la retropropagaci√≥n ajusta los par√°metros usando derivadas y la regla de la cadena.

  ### Analog√≠a para Entenderlo Mejor üí°
  Imagina una red neuronal como una f√°brica donde cada m√°quina (neurona) recibe materiales (entradas), los procesa con una receta (funci√≥n afin), luego aplica un toque especial (funci√≥n de activaci√≥n) para crear productos intermedios, que luego se ensamblan en la siguiente l√≠nea (capa). La retropropagaci√≥n es como una inspecci√≥n de calidad que corrige el proceso paso a paso para mejorar el producto final.


---

## üìñ Explicaci√≥n Completa y Sencilla

### üß© Neurona Artificial

Una neurona artificial recibe varias entradas, realiza un c√°lculo y produce un valor de activaci√≥n. Este c√°lculo tiene dos pasos fundamentales:

1. **Transformaci√≥n af√≠n:**  
   Se multiplica la entrada $x$ por una matriz de pesos $W$, y se suma un vector de sesgos $b$ (o $c$). Matem√°ticamente:  
   $$
   z = W^\top x + b
    $$
> üîß ¬øQu√© es un peso en una red neuronal?
Un peso es un n√∫mero que determina la importancia de una conexi√≥n entre dos neuronas. En una red neuronal, cada conexi√≥n entre una neurona de una capa y una neurona de la siguiente tiene un n√∫mero asociado: ese n√∫mero es el peso. 

2. **Funci√≥n de activaci√≥n no lineal:**  
   Sobre $z$ se aplica una funci√≥n no lineal $g(z)$ llamada **funci√≥n de activaci√≥n**, dando la salida:  
   $$
   h = g(z) = g(W^\top x + b)
   $$

> ‚ö†Ô∏è **Importante:** La no linealidad es fundamental. Si la funci√≥n de activaci√≥n fuera lineal, toda la red ser√≠a equivalente a una funci√≥n lineal, limitando mucho su capacidad para aprender patrones complejos.

---

### üîë Funciones de Activaci√≥n Comunes

- **Sigmoide Log√≠stica:**  
  $$
  g(z) = \sigma(z) = \frac{1}{1 + e^{-z}}
  $$  
  Se satura cuando $z$ es muy positivo o negativo, dificultando el aprendizaje por gradientes. No es recomendada para capas ocultas.

- **Tangente Hiperb√≥lica (tanh):**  
  $$
  g(z) = \tanh(z)
  $$  
  Similar a la sigmoide pero centrada en 0 ($\tanh(0) = 0$), lo que facilita el entrenamiento.

- **Unidad Lineal Rectificada (ReLU):**  
  $$
  g(z) = \max(0, z)
  $$  
  Muy popular por su simplicidad y eficiencia. La derivada es constante (1) cuando la unidad est√° activa, ayudando a un aprendizaje m√°s efectivo.

---

### üèó Arquitectura de un MLP (Perceptr√≥n Multicapa)

- **Capas:**  
  Las redes se organizan en grupos llamados capas, que se conectan secuencialmente.  
  - Capa de entrada: recibe la entrada $x$.  
  - Capas ocultas: procesan la informaci√≥n internamente, sin salidas expl√≠citas de entrenamiento.  
  - Capa de salida: produce el resultado final.

- **Dimensiones de pesos y sesgos:**  
  Para una capa con $n$ entradas y $p$ salidas, la matriz de pesos $W$ tiene dimensiones $p \times n$ y el vector de sesgos $b$ tiene dimensi√≥n $p$.

---

### ‚ñ∂Ô∏è Forward Propagation (Propagaci√≥n hacia adelante)

El proceso que calcula la salida a partir de una entrada $x$:

1. Inicializamos la activaci√≥n de la capa 0 con la entrada:  
   $$
   h^{(0)} = x
   $$

2. Para cada capa $k = 1, \ldots, L$, calculamos:  
   - Activaci√≥n lineal:  
     $$
     a^{(k)} = b^{(k)} + W^{(k)} h^{(k-1)}
     $$  
   - Salida con funci√≥n de activaci√≥n:  
     $$
     h^{(k)} = f(a^{(k)})
     $$

Finalmente, $h^{(L)}$ es la salida predicha $\hat{y}$.

---

### üéØ Funci√≥n de Coste

- **Entrop√≠a cruzada:**  
  Utilizada para clasificaci√≥n, mide la diferencia entre la distribuci√≥n real y la predicha.  
  Para clasificaci√≥n multiclase con $n$ clases y salida softmax:  
  $$
  \text{Coste} = - \sum_{i=1}^n y_i \log \hat{y}_i
  $$

- **Importancia:**  
  Cambiar de error cuadr√°tico a entrop√≠a cruzada fue un avance clave para mejorar el aprendizaje en redes con salidas sigmoides y softmax.

---

### üîÑ Backpropagation (Retropropagaci√≥n)

- **Definici√≥n:**  
  Algoritmo para calcular el gradiente de la funci√≥n de coste con respecto a cada par√°metro $\theta$, usando la regla de la cadena.

- **Regla de la cadena (simplificada):**  
  Para funciones compuestas $z = f(g(x))$, la derivada es:  
  $$
  \frac{dz}{dx} = \frac{dz}{dg} \cdot \frac{dg}{dx}
  $$

- **Para vectores:**  
  Si $\mathbf{y} = g(\mathbf{x})$ y $z = f(\mathbf{y})$,  
  $$
  \nabla_{\mathbf{x}} z = \left( \frac{\partial \mathbf{y}}{\partial \mathbf{x}} \right)^\top \nabla_{\mathbf{y}} z
  $$  
  donde $\frac{\partial \mathbf{y}}{\partial \mathbf{x}}$ es la matriz Jacobiana de $g$.

- **Funcionamiento:**  
  Comienza con el gradiente de la salida (1) y viaja hacia atr√°s en la red, multiplicando por las derivadas parciales en cada paso y sumando gradientes cuando hay m√∫ltiples caminos.

---

## ‚ú® Puntos Finales

* Las redes neuronales combinan transformaciones lineales y no lineales para modelar funciones complejas.  
* Las funciones de activaci√≥n no lineales son esenciales para que la red aprenda patrones √∫tiles.  
* La propagaci√≥n hacia adelante calcula la salida, mientras que la retropropagaci√≥n calcula gradientes para optimizar la red.  
* Entender estos conceptos es clave para construir y entrenar redes neuronales con herramientas como NumPy.

---


# üß† Anal√≥gica Sencilla para Entender Capas y Neuronas en Redes Neuronales

> "Visualizar una red neuronal como un equipo de analistas hace que su funcionamiento sea mucho m√°s claro."

---  
  ### Resumen Clave üìù
  Una capa en una red neuronal es como un equipo de analistas que trabajan simult√°neamente con la misma informaci√≥n. Cada neurona recibe toda la entrada de la capa anterior y produce su propio resultado. La capa de entrada es solo la recepci√≥n de datos, no realiza c√°lculo. La capa de salida da la decisi√≥n final, por ejemplo, la probabilidad de pertenencia a una clase.

  ### Analog√≠a para Entenderlo Mejor üí°
  Imagina que una capa es una fila de analistas en una oficina. El informe con los datos de entrada es distribuido a todos ellos, y cada analista (neurona) genera una conclusi√≥n. As√≠, una capa es un grupo de neuronas trabajando en paralelo, todas viendo el mismo "informe" pero aportando diferentes perspectivas.



---

## üìñ Explicaci√≥n Completa y Sencilla

### 1. Capas y Neuronas: La Capa de Entrada

- **La Entrada:**  
  Imagina que recibes un informe con varias p√°ginas; cada p√°gina es un dato de entrada.  
- **La Capa de Entrada:**  
  No es realmente una capa que hace c√°lculos, sino un "buz√≥n de entrada" que distribuye la informaci√≥n. Por ejemplo, si el informe tiene 2 p√°ginas, el buz√≥n tendr√° espacio para 2 datos.  
- **Primera Capa Oculta:**  
  Esta es la primera fila de analistas que toman todo el informe (todos los datos de entrada) y producen una conclusi√≥n individual cada uno. Si hay 4 analistas, habr√° 4 conclusiones basadas en los mismos datos.

**Clave:** Una capa es un conjunto de neuronas que trabajan en paralelo, todas reciben la misma informaci√≥n de la capa anterior.

---

### 2. La Capa de Salida: Tomando Decisiones

- **El Objetivo:**  
  Queremos que la red decida si un punto pertenece a la luna A o la luna B (decisi√≥n binaria).  
- **La Herramienta:**  
  Usamos una neurona con activaci√≥n **Sigmoide**, que convierte cualquier n√∫mero en un valor entre 0 y 1.  
- **Interpretaci√≥n:**  
  El resultado es una probabilidad. Por ejemplo:  
  - Resultado 0.9 ‚Üí muy probable que sea la luna B  
  - Resultado 0.1 ‚Üí muy poco probable que sea la luna B (probablemente luna A)  
  - Resultado 0.5 ‚Üí indecisi√≥n total

**Pregunta:** Para obtener ese √∫nico n√∫mero de probabilidad, ¬øcu√°ntas neuronas crees que necesitamos en la capa final?

---

### 3. La Capa Oculta: Decidiendo la Complejidad

- Usaremos **4 neuronas** en la capa oculta para comenzar.  
- Esto no es "la respuesta correcta", sino un **hiperpar√°metro**, una elecci√≥n de dise√±o.  

**Importancia del n√∫mero de neuronas ocultas:**  
- Pocas neuronas ‚Üí red muy simple que no capta bien los patrones (subajuste).  
- Muchas neuronas ‚Üí la red puede memorizar los datos, pero falla en datos nuevos (sobreajuste).  

4 neuronas es un buen punto medio para este problema: ni muy simple ni muy complejo.

---

### Resumen de Nuestra Arquitectura

| Capa           | N√∫mero de Neuronas             | Descripci√≥n                       |
|----------------|-------------------------------|---------------------------------|
| Capa de Entrada| `n_x` (definido por el usuario)| N√∫mero de datos de entrada       |
| Capa Oculta    | 4                             | N√∫mero fijo para empezar         |
| Capa de Salida | `n_y` (definido por el usuario)| N√∫mero de salidas (por ejemplo, 1 para binaria) |

---

## ‚ú® Puntos Finales

* La capa de entrada es solo el punto de partida para recibir datos, sin c√°lculos propios.  
* Cada neurona en una capa trabaja con toda la entrada que recibe, pero produce su propio valor √∫nico.  
* El n√∫mero de neuronas en capas ocultas es una decisi√≥n clave que afecta la capacidad de aprendizaje y generalizaci√≥n de la red.  
* La capa de salida traduce la informaci√≥n en decisiones concretas, usualmente en forma de probabilidades con funciones de activaci√≥n espec√≠ficas.


## ‚öôÔ∏è Implementaci√≥n: Preparando los Par√°metros Iniciales

### üß± Nuestra Estructura

Para implementar la red, vamos a utilizar la siguiente arquitectura:

- **Capa de Entrada** $(n_x)$: 2 neuronas  
  *(porque cada punto tiene 2 coordenadas: X e Y)*

- **Capa Oculta** $(n_h)$: 4 neuronas  
  *(suficiente capacidad para aprender la forma curva de las lunas)*

- **Capa de Salida** $(n_y)$: 1 neurona  
  *(queremos una √∫nica probabilidad como resultado final)*

---

### üß∞ Paso Siguiente: Obtener los "Materiales"

Para que la red neuronal funcione, necesitamos definir sus **par√°metros de entrenamiento**: los **pesos** ($W$) y los **biases** ($b$).

Tendremos **dos conjuntos** de par√°metros:

---

#### üîó 1. De la **Capa de Entrada** a la **Capa Oculta**:

- Matriz de pesos:  
  $$
  W_1 \in \mathbb{R}^{(4,\ 2)}
  $$

- Vector de bias:  
  $$
  b_1 \in \mathbb{R}^{(4,\ 1)}
  $$

---

#### üîó 2. De la **Capa Oculta** a la **Capa de Salida**:

- Matriz de pesos:  
  $$
  W_2 \in \mathbb{R}^{(1,\ 4)}
  $$

- Vector de bias:  
  $$
  b_2 \in \mathbb{R}^{(1,\ 1)}
  $$

---

Con estos par√°metros listos, estaremos en condiciones de construir la **funci√≥n de propagaci√≥n hacia adelante**, calcular el **costo**, y luego ajustar los par√°metros mediante **backpropagation**.



## üî¢ Matriz de Pesos y Vector de Bias: C√≥mo se Calculan y Por Qu√©



### üß† Conexi√≥n entre Capas: ¬øQu√© es una Matriz de Pesos?

Cuando conectamos dos capas en una red neuronal, necesitamos una **matriz de pesos** que defina c√≥mo se transmite la informaci√≥n desde una capa a otra. Esta matriz representa la "fuerza" de cada conexi√≥n entre neuronas.

---

### üìê Dimensiones de la Matriz de Pesos **W‚ÇÅ**

- **Contexto:** Conectamos la **capa de entrada** (de tama√±o 2) con la **capa oculta** (de tama√±o 4).  
- **Forma de la matriz:**  
  $$
  \text{Shape de } W_1 = (4,\ 2)
  $$

- **¬øPor qu√© (4, 2)?**  
  - Cada una de las 4 neuronas en la capa oculta recibe 2 entradas (una por cada neurona de entrada).
  - Esto significa que necesitamos **4 filas** (una por cada neurona de destino) y **2 columnas** (una por cada entrada).
  - **Regla general:**  
    $$
    \text{Shape de } W = (\text{dimensi√≥n de la capa de destino},\ \text{dimensi√≥n de la capa de origen})
    $$

---

### üßÆ Multiplicaci√≥n Matricial

Para que las operaciones funcionen correctamente en NumPy:

- **Vector de entrada:**  
  $$
  x = (2,\ 1)
  $$

- **Matriz de pesos:**  
  $$
  W_1 = (4,\ 2)
  $$

- **Multiplicaci√≥n:**  
  $$
  z = W_1 \cdot x \Rightarrow \text{Shape de } z = (4,\ 1)
  $$

As√≠, obtenemos un vector de 4 elementos: uno para cada neurona de la capa oculta. ¬°Justo lo que esper√°bamos!

---

### ‚ûï Vector de Bias **b‚ÇÅ**

Despu√©s de la multiplicaci√≥n con la matriz de pesos, cada neurona tambi√©n recibe un **bias** individual que se suma a su entrada ponderada. Es como un "desplazamiento personal" para cada neurona.

- **Forma del bias:**  
  $$
  \text{Shape de } b_1 = (4,)
  $$

- **¬øPor qu√© (4,)?**  
  Porque la **capa de destino** (la capa oculta) tiene 4 neuronas, y cada una necesita su propio bias.

---

### üß© Recapitulaci√≥n Visual

| Elemento         | Shape       | Significado                                       |
|------------------|-------------|--------------------------------------------------|
| `W‚ÇÅ`             | (4, 2)      | 4 neuronas de salida, 2 entradas cada una        |
| `x`              | (2, 1)      | Vector de entrada con 2 caracter√≠sticas          |
| `W‚ÇÅ ¬∑ x`         | (4, 1)      | Resultado: un valor por cada neurona oculta      |
| `b‚ÇÅ`             | (4,)        | Bias para cada una de las 4 neuronas ocultas     |

---

**¬øPor qu√© todo esto importa?**  
Porque estas dimensiones aseguran que las operaciones matem√°ticas se realicen correctamente y que la red tenga la capacidad de aprender adecuadamente. Si las dimensiones no coinciden, ¬°el c√≥digo simplemente no funcionar√°!

## üîó Conexi√≥n Final: Capa Oculta ‚Üí Capa de Salida


### üß† Matriz de Pesos **W‚ÇÇ**

Ahora conectamos la **capa oculta** con la **capa de salida**. Recordemos:

- La capa oculta tiene **4 neuronas**.
- La capa de salida tiene **1 sola neurona** (porque estamos haciendo una **clasificaci√≥n binaria**: luna A o luna B).

#### üî¢ Dimensi√≥n de la Matriz de Pesos:

$$
\text{Shape de } W_2 = (1,\ 4)
$$

- **¬øPor qu√© (1, 4)?**
  - La matriz conecta 4 valores de entrada (uno por cada neurona oculta) con 1 neurona de salida.
  - Siguiendo la convenci√≥n:
    $$
    \text{Shape de } W = (\text{dimensi√≥n de la capa de destino},\ \text{dimensi√≥n de la capa de origen})
    $$

---

### ‚ûï Vector de Bias **b‚ÇÇ**

Cada neurona en la capa de destino necesita su **bias** individual.

- Como la capa de salida tiene **una sola neurona**, el vector de bias tendr√°:
  $$
  \text{Shape de } b_2 = (1,)
  $$

---

### üß© Recapitulaci√≥n Visual

| Elemento         | Shape       | Significado                                          |
|------------------|-------------|-----------------------------------------------------|
| `W‚ÇÇ`             | (1, 4)      | 1 neurona de salida, conectada a 4 neuronas ocultas |
| `a‚ÇÅ`             | (4, 1)      | Activaciones de la capa oculta                      |
| `W‚ÇÇ ¬∑ a‚ÇÅ`        | (1, 1)      | Resultado: activaci√≥n de la √∫nica neurona de salida |
| `b‚ÇÇ`             | (1,)        | Bias para la √∫nica neurona de salida                |

---

**üß† ¬øQu√© obtiene la red al final?**

Un √∫nico n√∫mero entre 0 y 1 (gracias a la activaci√≥n sigmoide) que interpreta como la **probabilidad de que el punto pertenezca a la luna B**.


## üéØ ¬øPor qu√© inicializamos los pesos aleatoriamente?


### üí• El Problema Real: *Ruptura de Simetr√≠a* (Symmetry Breaking)

Supongamos que cometemos el error de inicializar **todos los pesos con ceros**.

---

### üîÅ Escenario Desastroso (Inicializaci√≥n con ceros)

Tenemos una **capa oculta con 4 neuronas**. Si todos los pesos de $W_1$ y los biases $b_1$ son cero, pasar√≠a lo siguiente:

#### 1. **Forward Pass**
Recibimos una entrada: $(x_1,\ x_2)$  
Cada neurona de la capa oculta calcular√°:

- Neurona 1: $x_1 \cdot 0 + x_2 \cdot 0 + 0 = 0$
- Neurona 2: $x_1 \cdot 0 + x_2 \cdot 0 + 0 = 0$
- Neurona 3: $x_1 \cdot 0 + x_2 \cdot 0 + 0 = 0$
- Neurona 4: $x_1 \cdot 0 + x_2 \cdot 0 + 0 = 0$

‚úÖ Todas producen **exactamente la misma salida**. Son **clones perfectos**.

---

#### 2. **Backward Pass (Retropropagaci√≥n)**

Ahora calculamos los gradientes. Como todas las neuronas dieron el mismo resultado, **reciben el mismo gradiente**.

- Todas ser√°n ajustadas **de la misma forma**.

---

#### 3. **Actualizaci√≥n de Pesos**

Sup√≥n que el gradiente para cierto peso es $g$ y usamos una tasa de aprendizaje $\alpha$.

- Peso actualizado: $0 - \alpha \cdot g$
- Resultado: **todos los pesos siguen siendo id√©nticos**

---

### üö® Consecuencia: La red nunca aprende

Estas neuronas nunca se diferenciar√°n unas de otras.  
Siempre producir√°n la misma salida ‚Üí recibir√°n el mismo error ‚Üí actualizar√°n sus pesos de la misma forma.

üëâ Es como tener **una sola neurona repetida 4 veces**, desperdiciando completamente la capacidad de la red.

---

### ‚úÖ La Soluci√≥n: Inicializaci√≥n Aleatoria

Para evitar ese desastre, **rompemos la simetr√≠a**:

- Los pesos $W_1$ y $W_2$ se inicializan con **valores peque√±os y aleatorios**
  $$
  W_1 \sim \mathcal{N}(0,\ \epsilon),\quad W_2 \sim \mathcal{N}(0,\ \epsilon)
  $$

Esto garantiza que:

- Cada neurona de la capa oculta empieza con una perspectiva distinta.
- Generan salidas diferentes desde el primer paso.
- Reciben gradientes diferentes y comienzan a **especializarse**.

---

### ‚ÑπÔ∏è ¬øY los Biases?

No hay problema en inicializarlos a cero.

- Cada $b_i$ afecta **solo a su neurona**.
- No hay "simetr√≠a entre biases" que deba romperse.

---

### üß† Conclusi√≥n

**Nunca inicialices todos los pesos a cero**.  
Si lo haces, tu red se volver√° una f√°brica de clones in√∫tiles.

‚úÖ Al usar pesos aleatorios, le das a cada neurona **una oportunidad de aprender cosas diferentes**, convirtiendo la red en un sistema verdaderamente inteligente.

como buena practica hacemos un diccionario donde podamos guardar los valores de la capas para nuestra duncion de inicialiacion de parametros de nuestra red neuronal.

## üöÄ Implementar la Propagaci√≥n hacia Adelante (Forward Propagation)


Ya tenemos nuestros par√°metros (`W1`, `b1`, `W2`, `b2`), as√≠ que ahora toca usarlos para hacer que la red funcione: **convertir una entrada $X$ en una predicci√≥n final**.

---

### üîÅ ¬øQu√© es la Propagaci√≥n hacia Adelante?

Es el proceso de pasar los datos de entrada **capa por capa**, hasta llegar a la salida de la red.

Para **cada capa**, el proceso tiene dos pasos:

1. **C√°lculo Lineal**  
   Se multiplican las activaciones de la capa anterior por los pesos y se les suma el bias:  
   **Z = W ‚ãÖ A(anterior) + b**

2. **C√°lculo de Activaci√≥n**  
   Se aplica una funci√≥n no lineal sobre $Z$ para obtener la activaci√≥n $A$:
   **A = activaci√≥n(Z)**

---

### üîê Capa Oculta

Usaremos `tanh` como funci√≥n de activaci√≥n.  
Este es el c√≥digo:

```python
Z1 = np.dot(W1, X1) + b1
A1 = np.tanh(Z1)
````

* `W1`: matriz de pesos con forma (4, 2)
* `X1`: vector o matriz de entrada con forma (2, m)
* `b1`: vector de bias con forma (4, 1)
* `A1`: salida activada de la capa oculta (4, m)

---

### üéØ Capa de Salida

Aqu√≠ usamos la funci√≥n **sigmoide**, ya que queremos una **salida entre 0 y 1**, √∫til para tareas de clasificaci√≥n binaria (como "¬øS√≠ o No?", "¬øClase 1 o Clase 0?").

```python
Z2 = np.dot(W2, A1) + b2
A2 = sigmoid(Z2)
```

Y previamente definimos la funci√≥n sigmoide:

```python
def sigmoid(z):
    return 1 / (1 + np.exp(-z))
```

* `W2`: matriz de pesos con forma (1, 4)
* `A1`: activaci√≥n de la capa oculta (4, m)
* `b2`: bias con forma (1, 1)
* `A2`: **predicci√≥n final de la red**, forma (1, m)

---

### üß† Detalle T√©cnico: ¬øPor qu√© el bias es (n, 1)?

Cuando calculamos:

```python
Z1 = np.dot(W1, X1) + b1
```

* `np.dot(W1, X1)` da una matriz de forma **(4, m)**.
* `b1` tiene forma **(4, 1)**.

Gracias al **broadcasting** de NumPy:

* NumPy extiende autom√°ticamente el vector columna `b1` para que se pueda sumar a cada columna del resultado sin error.
* Si en vez de `(4, 1)` usaras `(4,)`, NumPy **podr√≠a fallar** al hacer broadcasting correctamente, especialmente si cambian las dimensiones de entrada o se vectoriza el c√≥digo m√°s adelante.

‚úÖ **Usar forma (n, 1) en el bias es la opci√≥n m√°s robusta y clara.**

---

### üß™ Conclusi√≥n

La propagaci√≥n hacia adelante nos da la **predicci√≥n** de la red en funci√≥n de sus pesos y biases. Este paso es crucial porque:

* Nos permite evaluar qu√© tan bien est√° funcionando la red.
* Es la base para calcular el error y hacer la retropropagaci√≥n en el siguiente paso.

## üìâ Calcular la P√©rdida o Coste



### ¬øC√≥mo sabemos si la red est√° haciendo bien las predicciones?

Nuestra red toma un conjunto de datos de entrada **X** y devuelve predicciones **A2**. Pero para saber qu√© tan buena o mala es esa predicci√≥n, necesitamos **medir el error**.

Esto lo hacemos con una **funci√≥n de coste**, que compara las predicciones **A2** con las etiquetas reales **Y** (los valores verdaderos) y nos devuelve un n√∫mero que indica qu√© tan "equivocada" est√° la red.

---

### ‚öñÔ∏è Funci√≥n de coste elegida: Entrop√≠a Cruzada Binaria (BCE)

La funci√≥n de coste **Binary Cross-Entropy (BCE)** es ideal para problemas de clasificaci√≥n binaria (salida 0 o 1) y est√° definida as√≠:

$
J = -\frac{1}{m} \sum_{i=1}^m \left[ y^{(i)} \log(a^{(i)}) + (1 - y^{(i)}) \log(1 - a^{(i)}) \right]
$

donde:

- $m$ = n√∫mero de ejemplos de entrenamiento
- $y^{(i)}$ = etiqueta verdadera del ejemplo $i$
- $a^{(i)}$ = predicci√≥n de la red para el ejemplo $i$

---

### üìù Notaci√≥n: ¬øPor qu√© usamos \(Y\) may√∫scula en lugar de \(y\) min√∫scula?

- \( y \) min√∫scula normalmente se usa para **un solo vector** o ejemplo.
- \( Y \) may√∫scula indica que estamos trabajando con un **conjunto de datos completo** (matriz), con muchas etiquetas al mismo tiempo.

Nuestra funci√≥n de coste est√° dise√±ada para calcular el error en **todos los ejemplos a la vez**, operando con matrices \(X\) y \(Y\).

---

### üìä Relaci√≥n con Machine Learning cl√°sico

En modelos cl√°sicos de ML, la funci√≥n de coste suele recibir par√°metros como:

- $X$ (datos de entrada)
- $\theta$ (par√°metros del modelo)
- $\lambda$ (t√©rmino de regularizaci√≥n)

En nuestras redes neuronales, estos par√°metros est√°n desglosados en m√∫ltiples pasos:

- $X$: datos de entrada
- $W_1, b_1, W_2, b_2$: nuestros par√°metros (equivalente a $\theta$)
- Funciones intermedias: $Z_1$, $A_1$, $(Z_2)$, $A_2$ (c√°lculos dentro de la red)
- M√°s adelante, se puede agregar $\lambda$ para regularizaci√≥n

Por eso, **nuestro "theta" es el conjunto de par√°metros $\{W_1, b_1, W_2, b_2\}$** y **$\lambda$** lo a√±adiremos cuando hablemos de regularizaci√≥n.

---

### üßÆ Implementaci√≥n en Python

```python
def comput_cost(A2, Y):
    m = A2.shape[1]
    cost_sum = np.sum((Y * np.log(A2)) + ((1 - Y) * np.log(1 - A2)))
    cost_orig = - (1 / m) * cost_sum
    return cost_orig
```

* `A2`: matriz (1, m) con predicciones de la red
* `Y`: matriz (1, m) con etiquetas reales


### üß† Resumen

* La funci√≥n coste mide el error entre lo que predice la red y la realidad.
* Minimizar el coste es el objetivo del entrenamiento.
* Usamos entrop√≠a cruzada binaria para clasificaci√≥n binaria.
* Los par√°metros y c√°lculos de la red se distribuyen en varias variables, pero todo forma parte del modelo.



Con esta funci√≥n ya puedes saber cu√°n bien est√° funcionando tu red en cada paso. El siguiente paso ser√° usar esta medida para ajustar tus pesos y biases (¬°retropropagaci√≥n!).

## üîÑ Implementar Backpropagation (Retropropagaci√≥n)

### üéØ Objetivo

Queremos ajustar los **pesos (`W`)** y los **sesgos (`b`)** de nuestra red para que cometa **menos error**. Para eso, necesitamos saber c√≥mo cada par√°metro influye en el coste total, y eso se logra calculando los **gradientes**.

---

### ‚ùì ¬øQu√© es un gradiente y por qu√© lo necesitamos?

El **gradiente** de un par√°metro responde a esta pregunta:

> "Si cambio este par√°metro un poquito, ¬øcu√°nto y en qu√© direcci√≥n cambia el coste total?"

Este conocimiento nos permite modificar los par√°metros **en la direcci√≥n correcta para reducir el error** usando el algoritmo de **descenso de gradiente**.



## üß† Intuici√≥n detr√°s de la retropropagaci√≥n

Piensa en una "cadena de culpa":

1. Si el coste es alto, quiere decir que la predicci√≥n fue mala.
2. Retropropagamos ese error hacia atr√°s en la red para ver cu√°nta **"culpa"** tiene cada par√°metro (peso o sesgo).
3. As√≠ sabemos **qu√© ajustar** y **cu√°nto**.

Este proceso se basa en la **regla de la cadena** del c√°lculo diferencial.

---

### üîπ Paso 1: calcular el error de salida (`dZ2`)

La √∫ltima capa usa **funci√≥n sigmoide**, por eso su derivada es simple:

$
dZ2 = A2 - Y
$

Esto representa **el error entre lo que predijo la red (`A2`) y la verdad (`Y`)**.

---

### üîπ Paso 2: calcular gradientes de los par√°metros de salida

Sabemos que:

$
Z2 = W2 \cdot A1 + b2
$

Entonces aplicamos las derivadas:

- **`dW2 = dZ2 ‚ãÖ A1·µÄ`** ‚Üí mide cu√°nto debe ajustarse cada peso
- **`db2 = suma(dZ2)`** ‚Üí mide cu√°nto debe ajustarse cada sesgo


### üîÅ **Ese es el coraz√≥n de la *retro*propagaci√≥n**

La **predicci√≥n final (`A2`)** es donde se manifiesta el **error**. Ah√≠ es donde **podemos medir cu√°nto se equivoc√≥ la red** comparando con las etiquetas reales (`Y`).

Pero los par√°metros que generaron esa predicci√≥n (los pesos y sesgos de todas las capas) est√°n **m√°s atr√°s** en la red.

---

### üß† Entonces, ¬øpor qu√© ir desde atr√°s hacia adelante?

1. **El error lo puedes calcular solo cuando tienes la predicci√≥n (`A2`)**.
2. Para saber **c√≥mo ese error fue "causado" por los pesos anteriores**, debes ir **hacia atr√°s**, aplicando la **regla de la cadena** de la derivada.
3. As√≠ descubres:

   * Qu√© tan responsables son `W2` y `b2` del error.
   * Luego, qu√© tanto contribuyeron `W1` y `b1` a generar la activaci√≥n que luego gener√≥ el error.

---

### üîó Met√°fora sencilla:

Piensa en una f√°brica de botellas defectuosas.

* El defecto se nota **al final**, en la salida del producto.
* Pero para saber **d√≥nde estuvo el problema** (moldeo, llenado, tapado...), tienes que **revisar la l√≠nea de montaje en reversa** hasta encontrar qu√© paso contribuy√≥ al defecto.

Eso es retropropagaci√≥n: **"propagar el error hacia atr√°s"** para corregir donde realmente importa.

---

### ‚úÖ En resumen:

* Iniciamos con `dZ2 = A2 - Y` porque es **donde podemos medir el error**.
* Retrocedemos para calcular los efectos de ese error en los **par√°metros anteriores**.
* De ah√≠ el nombre: **retro** + **propagaci√≥n** = propagar el error hacia atr√°s.


## Implementaci√≥n de la Retropropagaci√≥n (Backpropagation)

Ahora que sabemos c√≥mo calcular la predicci√≥n de nuestra red (con la **propagaci√≥n hacia adelante**), necesitamos aprender c√≥mo **corregir los errores** que cometi√≥. Para eso usamos la **retropropagaci√≥n**.


### ¬øC√≥mo lo hacemos?

1. **Primero vemos el error en la salida**, es decir, cu√°nto se equivoc√≥ la predicci√≥n de la red respecto a la verdad.

2. Luego, **repartimos ese error hacia atr√°s** para saber cu√°nto afectaron los par√°metros de la √∫ltima capa, y luego los de la capa anterior, y as√≠ sucesivamente.

---

### Explicaci√≥n del c√≥digo paso a paso

```python
def backward_propagation(parameters, cache, X, Y):
```

Esta funci√≥n toma:

* `parameters`: los pesos de la red (en este caso s√≥lo `W2` que es el de la √∫ltima capa),
* `cache`: los valores que guardamos en la propagaci√≥n hacia adelante (las activaciones `A1` y `A2`),
* `X`: los datos de entrada originales,
* `Y`: las respuestas correctas (las etiquetas verdaderas).

---

```python
    W2 = parameters["W2"]
    A1 = cache["A1"]
    A2 = cache["A2"]
```

Aqu√≠ simplemente sacamos de la memoria los valores que necesitamos para hacer el c√°lculo.

---

```python
    m = A1.shape[1]  # n√∫mero de ejemplos
```

`m` es la cantidad de datos que estamos procesando a la vez. Lo usamos para hacer un promedio y no que un solo dato influya demasiado.

---

### Capa de salida (la √∫ltima capa)

```python
    dZ2 = A2 - Y
```

* Esto es el **error directo en la salida**.
* `A2` es la predicci√≥n que hizo la red,
* `Y` es la respuesta correcta.
* Restamos para saber cu√°nto nos equivocamos.

---

```python
    dW2 = (1/m) * (dZ2 @ A1.T)
```

* Aqu√≠ calculamos cu√°nto hay que cambiar cada peso `W2`.
* Multiplicamos ese error `dZ2` por lo que sali√≥ de la capa anterior (`A1`), pero transpuesto para que las dimensiones cuadren.
* Dividimos por `m` para promediar.

---

```python
    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)
```

* Aqu√≠ calculamos cu√°nto cambiar el sesgo `b2`.
* Sumamos todos los errores de los datos para cada neurona y hacemos promedio.

---

### Capa oculta (la capa anterior)

```python
    dA1 = W2.T @ dZ2
```

* Retropropagamos el error hacia atr√°s.
* Ahora vemos c√≥mo el error en la salida afecta a la capa oculta.
* Multiplicamos el error por la transpuesta de `W2` para repartir la ‚Äúculpa‚Äù entre las neuronas de la capa oculta.

---

```python
    dZ1 = dA1 * (1 - A1**2)
```

* Aqu√≠ aplicamos la derivada de la funci√≥n de activaci√≥n **tanh**.
* La derivada de tanh(z) es (1 - tanh(z)^2), y multiplicamos por `dA1` para ajustar el error a la activaci√≥n.

---

```python
    dW1 = (1/m) * np.dot(dZ1, X.T)
```

* Calculamos cu√°nto cambiar los pesos de la capa oculta.
* Multiplicamos el error ajustado (`dZ1`) por la entrada original `X` (transpuesta).
* Promediamos con `m`.

---

```python
    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)
```

* Calculamos cu√°nto cambiar el sesgo de la capa oculta.
* Sumamos todos los errores y promediamos.

---

### Guardamos todos los resultados para usarlos despu√©s

```python
    grads = {
        "dW1": dW1,
        "db1": db1,
        "dW2": dW2,
        "db2": db2
    }
    return grads
```

---

### En resumen:

* Calculamos el **error final** en la salida (`dZ2`).
* Usamos ese error para saber cu√°nto cambiar los pesos y sesgos de la capa final (`dW2`, `db2`).
* Luego, calculamos cu√°nto ese error afecta a la capa oculta (`dA1`).
* Ajustamos ese error con la derivada de la funci√≥n de activaci√≥n (`dZ1`).
* Calculamos cu√°nto cambiar los pesos y sesgos de la capa oculta (`dW1`, `db1`).
* Devolvemos todos estos cambios para poder actualizar nuestros par√°metros y mejorar la red.

## üîÑ Actualizar los Par√°metros: El Paso Clave para que la Red Aprenda

### ‚ùì ¬øPor qu√© actualizamos los par√°metros?

Imagina que est√°s en la cima de una monta√±a üèîÔ∏è, pero hay una **niebla tan densa** que no puedes ver hacia d√≥nde ir para bajar. Tu objetivo es encontrar el punto m√°s bajo ‚Äî el **valle**, donde el error de la red sea m√≠nimo.

* Cuando **inicializamos los par√°metros** (`initialize_parameters`), es como caer en un lugar aleatorio de esa monta√±a.
* La **altura** donde est√°s parado representa el **coste** o el **error** de la red.

  * Si est√°s **muy alto** ‚û°Ô∏è el error es **grande**.
  * Si est√°s **bajo** ‚û°Ô∏è el error es **peque√±o**.

---

### üß≠ ¬øC√≥mo sabemos hacia d√≥nde bajar?

No puedes ver el valle por la niebla, pero s√≠ puedes **sentir la pendiente** justo donde est√°s parado. Esa pendiente te indica la direcci√≥n de la subida m√°s fuerte, y t√∫ quieres ir en la direcci√≥n contraria, para bajar.

* Eso es lo que hace la **retropropagaci√≥n** (`backward_propagation`):
  üîç **Te dice cu√°l es la direcci√≥n de la pendiente (gradientes) m√°s pronunciada,**
  es decir, hacia d√≥nde sube m√°s el error.

* El resultado son los **gradientes** (`grads`), que nos dicen:
  üëâ **‚ÄúQu√© tanto‚Äù** y **‚Äúen qu√© direcci√≥n‚Äù** est√°n subiendo los errores para cada par√°metro.

---

### üèÉ‚Äç‚ôÇÔ∏è ¬øY luego qu√© hacemos?

Sabemos la direcci√≥n de subida, entonces **damos un paso peque√±o en la direcci√≥n opuesta** para bajar la monta√±a.

* Esto es la **actualizaci√≥n de par√°metros** (`update_parameters`).
* La f√≥rmula clave es:

```markdown
par√°metro_nuevo = par√°metro_viejo - tasa_de_aprendizaje √ó gradiente
```

* üìè **La tasa de aprendizaje** es el tama√±o del paso que damos.

  * Si es muy grande ‚ö†Ô∏è, podr√≠amos pasarnos del valle.
  * Si es muy peque√±o üê¢, tardamos mucho en llegar.

---

### üåü Resumen de la analog√≠a:

| üõ†Ô∏è Paso                   | üèîÔ∏è En la monta√±a                        | ü§ñ En la red neuronal                                      |
| -------------------------- | ---------------------------------------- | ---------------------------------------------------------- |
| üé≤ Inicializar par√°metros  | Caer en un punto aleatorio               | Asignar pesos y sesgos aleatorios                          |
| üë£ Sentir la pendiente     | Sentir la inclinaci√≥n del suelo          | Calcular gradientes con retropropagaci√≥n                   |
| ‚¨áÔ∏è Dar un paso hacia abajo | Caminar en direcci√≥n opuesta a la subida | Actualizar par√°metros con gradientes y tasa de aprendizaje |
| üîÅ Repetir muchas veces    | Seguir caminando hasta el valle          | Entrenar la red para minimizar el error                    |

---

### üéØ ¬øQu√© logramos con esto?

Cada paso que damos hace que el **coste baje poco a poco**. Nuestra red mejora sus predicciones y aprende a partir de los datos.

Este ciclo:
üîÅ **Calcular error ‚Üí calcular gradientes ‚Üí actualizar par√°metros**
es lo que permite a la red **aprender de sus errores** y ajustar sus "conexiones" para ser cada vez m√°s precisa.


## üîÑ Iteraci√≥n: ¬øPor qu√© repetir los pasitos?

Una sola vez NO alcanza para que la red aprenda bien. ¬°Es como querer bajar una monta√±a con un solo paso! üèîÔ∏èüë£

---

### üéØ El entrenamiento es un proceso repetitivo:

1. üöÄ **Forward pass:**
   Calculamos la salida de la red y cu√°nto se equivoc√≥.

2. üéØ **Calcular el costo:**
   Medimos qu√© tan grande es ese error.

3. üîô **Backward pass:**
   Calculamos los gradientes, es decir, hacia d√≥nde y cu√°nto ajustar para mejorar.

4. üèÉ‚Äç‚ôÇÔ∏è **Actualizar par√°metros:**
   Damos un peque√±o paso ajustando pesos y sesgos para bajar el error.

---

### üîÅ ¬øY qu√© pasa con todo esto?

Hay que repetir este ciclo **much√≠simas veces**, para que la red mejore poco a poco. Cada repetici√≥n se llama:

* **Iteraci√≥n** o
* **Epoch**

---

### üßó‚Äç‚ôÇÔ∏è Met√°fora para entenderlo mejor:

Imagin√° que est√°s bajando una monta√±a en plena niebla.

* Un solo paso no te lleva hasta el valle.
* Necesit√°s dar **muchos pasitos peque√±os, uno tras otro**.

Solo as√≠, poco a poco, vas acerc√°ndote al punto m√°s bajo donde el error es m√≠nimo.

---

### ‚öôÔ∏è Entonces, armamos un bucle (loop) que repite:

> Forward ‚Üí Costo ‚Üí Backward ‚Üí Actualizar

... muchas veces, para que la red aprenda de verdad.

## üß† Entrenar Nuestra Red Neuronal

Ahora vamos a juntar todo lo que aprendimos para construir y **entrenar nuestra red neuronal**.
Esto incluye: preparar los datos, definir la arquitectura, entrenar el modelo y visualizar los resultados.

---

### üì• Paso 1: Cargar el Dataset `make_moons`

Usamos `make_moons` porque genera datos con forma de medialuna:
una medialuna para la clase 0, y otra para la clase 1. ¬°Ideal para probar modelos no lineales!

```python
X, Y = make_moons(n_samples=400, noise=0.2)
```

* `n_samples=400`: generamos 400 puntos.
* `noise=0.2`: le agregamos ruido para hacerlo m√°s realista.

---

### üîÑ Paso 2: Reorganizar los Datos

> üí° **¬øPor qu√© reorganizamos X y Y?**

Porque al trabajar con redes neuronales y NumPy, **es m√°s eficiente que cada columna sea un ejemplo**, en vez de cada fila.

```python
X = X.T        # De (400, 2) a (2, 400)
Y = Y.reshape(1, -1)  # De (400,) a (1, 400)
```

Esto permite hacer operaciones vectorizadas como:

```python
Z = np.dot(W, X) + b
```

¬°Sin bucles! M√°s r√°pido y m√°s limpio üßº

---

### üëÄ Paso 3: Visualizar los Datos

Antes de entrenar, **miramos c√≥mo se ven los datos**:

![alt text](<Scatter plot of make_moon dataset.png>)

---

### üß† Paso 4: Entrenar la Red Neuronal

Ahora s√≠, ¬°el coraz√≥n del proyecto!
Entrenamos la red con 1 capa oculta de 4 neuronas, durante 10.000 iteraciones:

```python
trained_parameters, costs = nn_model(X, Y, n_h=4, num_iterations=10000, learning_rate=1.2)
```

* `n_h=4`: 4 neuronas en la capa oculta.
* `learning_rate=1.2`: cu√°n grandes son los pasitos que damos.
* `num_iterations=10000`: cu√°ntas veces vamos a repetir el proceso de aprendizaje.

---

### üìä Paso 5: Visualizar la Frontera de Decisi√≥n

¬øQu√© tan bien aprendi√≥ nuestra red?
Veamos c√≥mo separa las dos clases visualmente üëá

```python
plot_decision_boundary(lambda x: predict(trained_parameters, x), X, Y)
```

Esto genera una gr√°fica como esta:

![alt text](<Decision boundary.png>)

---

### üìâ Paso 6: Ver c√≥mo baja el Costo

Durante el entrenamiento, registramos c√≥mo fue bajando el error:

```python
plt.plot(costs)
plt.xlabel("iterations (per thousands)")
plt.ylabel("cost")
plt.title("Cost reduction over time")
plt.show()
```

Esto nos permite ver si el modelo **est√° aprendiendo** correctamente o no:

* üìâ Si baja ‚Üí vamos bien.
* üìà Si sube o no baja ‚Üí problema (por ejemplo, learning rate muy alto).

![alt text](<Cost reduction overtime.png>)

---

### üß™ Paso Extra: Semilla Fija para Resultados Reproducibles

Para que siempre obtengamos el mismo resultado (√∫til para pruebas y debugging):

```python
np.random.seed(42)
```

---

## üß© ¬øQu√© hace la funci√≥n `nn_model()`?

Esta es la funci√≥n que **entrena todo el modelo**.
Combina todos los pasos clave:

* Inicializar los par√°metros
* Forward propagation
* C√°lculo del costo
* Backward propagation
* Actualizar los par√°metros
* Repetir todo esto por muchas iteraciones

