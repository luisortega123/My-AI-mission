# ğŸ§  Red Neuronal con NumPy: 

> â€œEntender una red neuronal es descomponer la magia en matemÃ¡ticas y funciones simples.â€

---
  ### Resumen Clave ğŸ“
  Una red neuronal artificial transforma entradas mediante combinaciones lineales y funciones no lineales llamadas activaciones para aprender patrones complejos. La propagaciÃ³n hacia adelante calcula salidas, mientras que la retropropagaciÃ³n ajusta los parÃ¡metros usando derivadas y la regla de la cadena.

  ### AnalogÃ­a para Entenderlo Mejor ğŸ’¡
  Imagina una red neuronal como una fÃ¡brica donde cada mÃ¡quina (neurona) recibe materiales (entradas), los procesa con una receta (funciÃ³n afin), luego aplica un toque especial (funciÃ³n de activaciÃ³n) para crear productos intermedios, que luego se ensamblan en la siguiente lÃ­nea (capa). La retropropagaciÃ³n es como una inspecciÃ³n de calidad que corrige el proceso paso a paso para mejorar el producto final.


---

## ğŸ“– ExplicaciÃ³n Completa y Sencilla

### ğŸ§© Neurona Artificial

Una neurona artificial recibe varias entradas, realiza un cÃ¡lculo y produce un valor de activaciÃ³n. Este cÃ¡lculo tiene dos pasos fundamentales:

1. **TransformaciÃ³n afÃ­n:**  
   Se multiplica la entrada $x$ por una matriz de pesos $W$, y se suma un vector de sesgos $b$ (o $c$). MatemÃ¡ticamente:  
   $$
   z = W^\top x + b
    $$
> ğŸ”§ Â¿QuÃ© es un peso en una red neuronal?
Un peso es un nÃºmero que determina la importancia de una conexiÃ³n entre dos neuronas. En una red neuronal, cada conexiÃ³n entre una neurona de una capa y una neurona de la siguiente tiene un nÃºmero asociado: ese nÃºmero es el peso. 

2. **FunciÃ³n de activaciÃ³n no lineal:**  
   Sobre $z$ se aplica una funciÃ³n no lineal $g(z)$ llamada **funciÃ³n de activaciÃ³n**, dando la salida:  
   $$
   h = g(z) = g(W^\top x + b)
   $$

> âš ï¸ **Importante:** La no linealidad es fundamental. Si la funciÃ³n de activaciÃ³n fuera lineal, toda la red serÃ­a equivalente a una funciÃ³n lineal, limitando mucho su capacidad para aprender patrones complejos.

---

### ğŸ”‘ Funciones de ActivaciÃ³n Comunes

- **Sigmoide LogÃ­stica:**  
  $$
  g(z) = \sigma(z) = \frac{1}{1 + e^{-z}}
  $$  
  Se satura cuando $z$ es muy positivo o negativo, dificultando el aprendizaje por gradientes. No es recomendada para capas ocultas.

- **Tangente HiperbÃ³lica (tanh):**  
  $$
  g(z) = \tanh(z)
  $$  
  Similar a la sigmoide pero centrada en 0 ($\tanh(0) = 0$), lo que facilita el entrenamiento.

- **Unidad Lineal Rectificada (ReLU):**  
  $$
  g(z) = \max(0, z)
  $$  
  Muy popular por su simplicidad y eficiencia. La derivada es constante (1) cuando la unidad estÃ¡ activa, ayudando a un aprendizaje mÃ¡s efectivo.

---

### ğŸ— Arquitectura de un MLP (PerceptrÃ³n Multicapa)

- **Capas:**  
  Las redes se organizan en grupos llamados capas, que se conectan secuencialmente.  
  - Capa de entrada: recibe la entrada $x$.  
  - Capas ocultas: procesan la informaciÃ³n internamente, sin salidas explÃ­citas de entrenamiento.  
  - Capa de salida: produce el resultado final.

- **Dimensiones de pesos y sesgos:**  
  Para una capa con $n$ entradas y $p$ salidas, la matriz de pesos $W$ tiene dimensiones $p \times n$ y el vector de sesgos $b$ tiene dimensiÃ³n $p$.

---

### â–¶ï¸ Forward Propagation (PropagaciÃ³n hacia adelante)

El proceso que calcula la salida a partir de una entrada $x$:

1. Inicializamos la activaciÃ³n de la capa 0 con la entrada:  
   $$
   h^{(0)} = x
   $$

2. Para cada capa $k = 1, \ldots, L$, calculamos:  
   - ActivaciÃ³n lineal:  
     $$
     a^{(k)} = b^{(k)} + W^{(k)} h^{(k-1)}
     $$  
   - Salida con funciÃ³n de activaciÃ³n:  
     $$
     h^{(k)} = f(a^{(k)})
     $$

Finalmente, $h^{(L)}$ es la salida predicha $\hat{y}$.

---

### ğŸ¯ FunciÃ³n de Coste

- **EntropÃ­a cruzada:**  
  Utilizada para clasificaciÃ³n, mide la diferencia entre la distribuciÃ³n real y la predicha.  
  Para clasificaciÃ³n multiclase con $n$ clases y salida softmax:  
  $$
  \text{Coste} = - \sum_{i=1}^n y_i \log \hat{y}_i
  $$

- **Importancia:**  
  Cambiar de error cuadrÃ¡tico a entropÃ­a cruzada fue un avance clave para mejorar el aprendizaje en redes con salidas sigmoides y softmax.

---

### ğŸ”„ Backpropagation (RetropropagaciÃ³n)

- **DefiniciÃ³n:**  
  Algoritmo para calcular el gradiente de la funciÃ³n de coste con respecto a cada parÃ¡metro $\theta$, usando la regla de la cadena.

- **Regla de la cadena (simplificada):**  
  Para funciones compuestas $z = f(g(x))$, la derivada es:  
  $$
  \frac{dz}{dx} = \frac{dz}{dg} \cdot \frac{dg}{dx}
  $$

- **Para vectores:**  
  Si $\mathbf{y} = g(\mathbf{x})$ y $z = f(\mathbf{y})$,  
  $$
  \nabla_{\mathbf{x}} z = \left( \frac{\partial \mathbf{y}}{\partial \mathbf{x}} \right)^\top \nabla_{\mathbf{y}} z
  $$  
  donde $\frac{\partial \mathbf{y}}{\partial \mathbf{x}}$ es la matriz Jacobiana de $g$.

- **Funcionamiento:**  
  Comienza con el gradiente de la salida (1) y viaja hacia atrÃ¡s en la red, multiplicando por las derivadas parciales en cada paso y sumando gradientes cuando hay mÃºltiples caminos.

---

## âœ¨ Puntos Finales

* Las redes neuronales combinan transformaciones lineales y no lineales para modelar funciones complejas.  
* Las funciones de activaciÃ³n no lineales son esenciales para que la red aprenda patrones Ãºtiles.  
* La propagaciÃ³n hacia adelante calcula la salida, mientras que la retropropagaciÃ³n calcula gradientes para optimizar la red.  
* Entender estos conceptos es clave para construir y entrenar redes neuronales con herramientas como NumPy.

---


# ğŸ§  AnalÃ³gica Sencilla para Entender Capas y Neuronas en Redes Neuronales

> "Visualizar una red neuronal como un equipo de analistas hace que su funcionamiento sea mucho mÃ¡s claro."

---  
  ### Resumen Clave ğŸ“
  Una capa en una red neuronal es como un equipo de analistas que trabajan simultÃ¡neamente con la misma informaciÃ³n. Cada neurona recibe toda la entrada de la capa anterior y produce su propio resultado. La capa de entrada es solo la recepciÃ³n de datos, no realiza cÃ¡lculo. La capa de salida da la decisiÃ³n final, por ejemplo, la probabilidad de pertenencia a una clase.

  ### AnalogÃ­a para Entenderlo Mejor ğŸ’¡
  Imagina que una capa es una fila de analistas en una oficina. El informe con los datos de entrada es distribuido a todos ellos, y cada analista (neurona) genera una conclusiÃ³n. AsÃ­, una capa es un grupo de neuronas trabajando en paralelo, todas viendo el mismo "informe" pero aportando diferentes perspectivas.



---

## ğŸ“– ExplicaciÃ³n Completa y Sencilla

### 1. Capas y Neuronas: La Capa de Entrada

- **La Entrada:**  
  Imagina que recibes un informe con varias pÃ¡ginas; cada pÃ¡gina es un dato de entrada.  
- **La Capa de Entrada:**  
  No es realmente una capa que hace cÃ¡lculos, sino un "buzÃ³n de entrada" que distribuye la informaciÃ³n. Por ejemplo, si el informe tiene 2 pÃ¡ginas, el buzÃ³n tendrÃ¡ espacio para 2 datos.  
- **Primera Capa Oculta:**  
  Esta es la primera fila de analistas que toman todo el informe (todos los datos de entrada) y producen una conclusiÃ³n individual cada uno. Si hay 4 analistas, habrÃ¡ 4 conclusiones basadas en los mismos datos.

**Clave:** Una capa es un conjunto de neuronas que trabajan en paralelo, todas reciben la misma informaciÃ³n de la capa anterior.

---

### 2. La Capa de Salida: Tomando Decisiones

- **El Objetivo:**  
  Queremos que la red decida si un punto pertenece a la luna A o la luna B (decisiÃ³n binaria).  
- **La Herramienta:**  
  Usamos una neurona con activaciÃ³n **Sigmoide**, que convierte cualquier nÃºmero en un valor entre 0 y 1.  
- **InterpretaciÃ³n:**  
  El resultado es una probabilidad. Por ejemplo:  
  - Resultado 0.9 â†’ muy probable que sea la luna B  
  - Resultado 0.1 â†’ muy poco probable que sea la luna B (probablemente luna A)  
  - Resultado 0.5 â†’ indecisiÃ³n total

**Pregunta:** Para obtener ese Ãºnico nÃºmero de probabilidad, Â¿cuÃ¡ntas neuronas crees que necesitamos en la capa final?

---

### 3. La Capa Oculta: Decidiendo la Complejidad

- Usaremos **4 neuronas** en la capa oculta para comenzar.  
- Esto no es "la respuesta correcta", sino un **hiperparÃ¡metro**, una elecciÃ³n de diseÃ±o.  

**Importancia del nÃºmero de neuronas ocultas:**  
- Pocas neuronas â†’ red muy simple que no capta bien los patrones (subajuste).  
- Muchas neuronas â†’ la red puede memorizar los datos, pero falla en datos nuevos (sobreajuste).  

4 neuronas es un buen punto medio para este problema: ni muy simple ni muy complejo.

---

### Resumen de Nuestra Arquitectura

| Capa           | NÃºmero de Neuronas             | DescripciÃ³n                       |
|----------------|-------------------------------|---------------------------------|
| Capa de Entrada| `n_x` (definido por el usuario)| NÃºmero de datos de entrada       |
| Capa Oculta    | 4                             | NÃºmero fijo para empezar         |
| Capa de Salida | `n_y` (definido por el usuario)| NÃºmero de salidas (por ejemplo, 1 para binaria) |

---

## âœ¨ Puntos Finales

* La capa de entrada es solo el punto de partida para recibir datos, sin cÃ¡lculos propios.  
* Cada neurona en una capa trabaja con toda la entrada que recibe, pero produce su propio valor Ãºnico.  
* El nÃºmero de neuronas en capas ocultas es una decisiÃ³n clave que afecta la capacidad de aprendizaje y generalizaciÃ³n de la red.  
* La capa de salida traduce la informaciÃ³n en decisiones concretas, usualmente en forma de probabilidades con funciones de activaciÃ³n especÃ­ficas.


## âš™ï¸ ImplementaciÃ³n: Preparando los ParÃ¡metros Iniciales

### ğŸ§± Nuestra Estructura

Para implementar la red, vamos a utilizar la siguiente arquitectura:

- **Capa de Entrada** $(n_x)$: 2 neuronas  
  *(porque cada punto tiene 2 coordenadas: X e Y)*

- **Capa Oculta** $(n_h)$: 4 neuronas  
  *(suficiente capacidad para aprender la forma curva de las lunas)*

- **Capa de Salida** $(n_y)$: 1 neurona  
  *(queremos una Ãºnica probabilidad como resultado final)*

---

### ğŸ§° Paso Siguiente: Obtener los "Materiales"

Para que la red neuronal funcione, necesitamos definir sus **parÃ¡metros de entrenamiento**: los **pesos** ($W$) y los **biases** ($b$).

Tendremos **dos conjuntos** de parÃ¡metros:

---

#### ğŸ”— 1. De la **Capa de Entrada** a la **Capa Oculta**:

- Matriz de pesos:  
  $$
  W_1 \in \mathbb{R}^{(4,\ 2)}
  $$

- Vector de bias:  
  $$
  b_1 \in \mathbb{R}^{(4,\ 1)}
  $$

---

#### ğŸ”— 2. De la **Capa Oculta** a la **Capa de Salida**:

- Matriz de pesos:  
  $$
  W_2 \in \mathbb{R}^{(1,\ 4)}
  $$

- Vector de bias:  
  $$
  b_2 \in \mathbb{R}^{(1,\ 1)}
  $$

---

Con estos parÃ¡metros listos, estaremos en condiciones de construir la **funciÃ³n de propagaciÃ³n hacia adelante**, calcular el **costo**, y luego ajustar los parÃ¡metros mediante **backpropagation**.



## ğŸ”¢ Matriz de Pesos y Vector de Bias: CÃ³mo se Calculan y Por QuÃ©



### ğŸ§  ConexiÃ³n entre Capas: Â¿QuÃ© es una Matriz de Pesos?

Cuando conectamos dos capas en una red neuronal, necesitamos una **matriz de pesos** que defina cÃ³mo se transmite la informaciÃ³n desde una capa a otra. Esta matriz representa la "fuerza" de cada conexiÃ³n entre neuronas.

---

### ğŸ“ Dimensiones de la Matriz de Pesos **Wâ‚**

- **Contexto:** Conectamos la **capa de entrada** (de tamaÃ±o 2) con la **capa oculta** (de tamaÃ±o 4).  
- **Forma de la matriz:**  
  $$
  \text{Shape de } W_1 = (4,\ 2)
  $$

- **Â¿Por quÃ© (4, 2)?**  
  - Cada una de las 4 neuronas en la capa oculta recibe 2 entradas (una por cada neurona de entrada).
  - Esto significa que necesitamos **4 filas** (una por cada neurona de destino) y **2 columnas** (una por cada entrada).
  - **Regla general:**  
    $$
    \text{Shape de } W = (\text{dimensiÃ³n de la capa de destino},\ \text{dimensiÃ³n de la capa de origen})
    $$

---

### ğŸ§® MultiplicaciÃ³n Matricial

Para que las operaciones funcionen correctamente en NumPy:

- **Vector de entrada:**  
  $$
  x = (2,\ 1)
  $$

- **Matriz de pesos:**  
  $$
  W_1 = (4,\ 2)
  $$

- **MultiplicaciÃ³n:**  
  $$
  z = W_1 \cdot x \Rightarrow \text{Shape de } z = (4,\ 1)
  $$

AsÃ­, obtenemos un vector de 4 elementos: uno para cada neurona de la capa oculta. Â¡Justo lo que esperÃ¡bamos!

---

### â• Vector de Bias **bâ‚**

DespuÃ©s de la multiplicaciÃ³n con la matriz de pesos, cada neurona tambiÃ©n recibe un **bias** individual que se suma a su entrada ponderada. Es como un "desplazamiento personal" para cada neurona.

- **Forma del bias:**  
  $$
  \text{Shape de } b_1 = (4,)
  $$

- **Â¿Por quÃ© (4,)?**  
  Porque la **capa de destino** (la capa oculta) tiene 4 neuronas, y cada una necesita su propio bias.

---

### ğŸ§© RecapitulaciÃ³n Visual

| Elemento         | Shape       | Significado                                       |
|------------------|-------------|--------------------------------------------------|
| `Wâ‚`             | (4, 2)      | 4 neuronas de salida, 2 entradas cada una        |
| `x`              | (2, 1)      | Vector de entrada con 2 caracterÃ­sticas          |
| `Wâ‚ Â· x`         | (4, 1)      | Resultado: un valor por cada neurona oculta      |
| `bâ‚`             | (4,)        | Bias para cada una de las 4 neuronas ocultas     |

---

**Â¿Por quÃ© todo esto importa?**  
Porque estas dimensiones aseguran que las operaciones matemÃ¡ticas se realicen correctamente y que la red tenga la capacidad de aprender adecuadamente. Si las dimensiones no coinciden, Â¡el cÃ³digo simplemente no funcionarÃ¡!

## ğŸ”— ConexiÃ³n Final: Capa Oculta â†’ Capa de Salida


### ğŸ§  Matriz de Pesos **Wâ‚‚**

Ahora conectamos la **capa oculta** con la **capa de salida**. Recordemos:

- La capa oculta tiene **4 neuronas**.
- La capa de salida tiene **1 sola neurona** (porque estamos haciendo una **clasificaciÃ³n binaria**: luna A o luna B).

#### ğŸ”¢ DimensiÃ³n de la Matriz de Pesos:

$$
\text{Shape de } W_2 = (1,\ 4)
$$

- **Â¿Por quÃ© (1, 4)?**
  - La matriz conecta 4 valores de entrada (uno por cada neurona oculta) con 1 neurona de salida.
  - Siguiendo la convenciÃ³n:
    $$
    \text{Shape de } W = (\text{dimensiÃ³n de la capa de destino},\ \text{dimensiÃ³n de la capa de origen})
    $$

---

### â• Vector de Bias **bâ‚‚**

Cada neurona en la capa de destino necesita su **bias** individual.

- Como la capa de salida tiene **una sola neurona**, el vector de bias tendrÃ¡:
  $$
  \text{Shape de } b_2 = (1,)
  $$

---

### ğŸ§© RecapitulaciÃ³n Visual

| Elemento         | Shape       | Significado                                          |
|------------------|-------------|-----------------------------------------------------|
| `Wâ‚‚`             | (1, 4)      | 1 neurona de salida, conectada a 4 neuronas ocultas |
| `aâ‚`             | (4, 1)      | Activaciones de la capa oculta                      |
| `Wâ‚‚ Â· aâ‚`        | (1, 1)      | Resultado: activaciÃ³n de la Ãºnica neurona de salida |
| `bâ‚‚`             | (1,)        | Bias para la Ãºnica neurona de salida                |

---

**ğŸ§  Â¿QuÃ© obtiene la red al final?**

Un Ãºnico nÃºmero entre 0 y 1 (gracias a la activaciÃ³n sigmoide) que interpreta como la **probabilidad de que el punto pertenezca a la luna B**.


## ğŸ¯ Â¿Por quÃ© inicializamos los pesos aleatoriamente?


### ğŸ’¥ El Problema Real: *Ruptura de SimetrÃ­a* (Symmetry Breaking)

Supongamos que cometemos el error de inicializar **todos los pesos con ceros**.

---

### ğŸ” Escenario Desastroso (InicializaciÃ³n con ceros)

Tenemos una **capa oculta con 4 neuronas**. Si todos los pesos de $W_1$ y los biases $b_1$ son cero, pasarÃ­a lo siguiente:

#### 1. **Forward Pass**
Recibimos una entrada: $(x_1,\ x_2)$  
Cada neurona de la capa oculta calcularÃ¡:

- Neurona 1: $x_1 \cdot 0 + x_2 \cdot 0 + 0 = 0$
- Neurona 2: $x_1 \cdot 0 + x_2 \cdot 0 + 0 = 0$
- Neurona 3: $x_1 \cdot 0 + x_2 \cdot 0 + 0 = 0$
- Neurona 4: $x_1 \cdot 0 + x_2 \cdot 0 + 0 = 0$

âœ… Todas producen **exactamente la misma salida**. Son **clones perfectos**.

---

#### 2. **Backward Pass (RetropropagaciÃ³n)**

Ahora calculamos los gradientes. Como todas las neuronas dieron el mismo resultado, **reciben el mismo gradiente**.

- Todas serÃ¡n ajustadas **de la misma forma**.

---

#### 3. **ActualizaciÃ³n de Pesos**

SupÃ³n que el gradiente para cierto peso es $g$ y usamos una tasa de aprendizaje $\alpha$.

- Peso actualizado: $0 - \alpha \cdot g$
- Resultado: **todos los pesos siguen siendo idÃ©nticos**

---

### ğŸš¨ Consecuencia: La red nunca aprende

Estas neuronas nunca se diferenciarÃ¡n unas de otras.  
Siempre producirÃ¡n la misma salida â†’ recibirÃ¡n el mismo error â†’ actualizarÃ¡n sus pesos de la misma forma.

ğŸ‘‰ Es como tener **una sola neurona repetida 4 veces**, desperdiciando completamente la capacidad de la red.

---

### âœ… La SoluciÃ³n: InicializaciÃ³n Aleatoria

Para evitar ese desastre, **rompemos la simetrÃ­a**:

- Los pesos $W_1$ y $W_2$ se inicializan con **valores pequeÃ±os y aleatorios**
  $$
  W_1 \sim \mathcal{N}(0,\ \epsilon),\quad W_2 \sim \mathcal{N}(0,\ \epsilon)
  $$

Esto garantiza que:

- Cada neurona de la capa oculta empieza con una perspectiva distinta.
- Generan salidas diferentes desde el primer paso.
- Reciben gradientes diferentes y comienzan a **especializarse**.

---

### â„¹ï¸ Â¿Y los Biases?

No hay problema en inicializarlos a cero.

- Cada $b_i$ afecta **solo a su neurona**.
- No hay "simetrÃ­a entre biases" que deba romperse.

---

### ğŸ§  ConclusiÃ³n

**Nunca inicialices todos los pesos a cero**.  
Si lo haces, tu red se volverÃ¡ una fÃ¡brica de clones inÃºtiles.

âœ… Al usar pesos aleatorios, le das a cada neurona **una oportunidad de aprender cosas diferentes**, convirtiendo la red en un sistema verdaderamente inteligente.

como buena practica hacemos un diccionario donde podamos guardar los valores de la capas para nuestra duncion de inicialiacion de parametros de nuestra red neuronal.

## ğŸš€ Implementar la PropagaciÃ³n hacia Adelante (Forward Propagation)


Ya tenemos nuestros parÃ¡metros (`W1`, `b1`, `W2`, `b2`), asÃ­ que ahora toca usarlos para hacer que la red funcione: **convertir una entrada $X$ en una predicciÃ³n final**.

---

### ğŸ” Â¿QuÃ© es la PropagaciÃ³n hacia Adelante?

Es el proceso de pasar los datos de entrada **capa por capa**, hasta llegar a la salida de la red.

Para **cada capa**, el proceso tiene dos pasos:

1. **CÃ¡lculo Lineal**  
   Se multiplican las activaciones de la capa anterior por los pesos y se les suma el bias:  
   **Z = W â‹… A(anterior) + b**

2. **CÃ¡lculo de ActivaciÃ³n**  
   Se aplica una funciÃ³n no lineal sobre $Z$ para obtener la activaciÃ³n $A$:
   **A = activaciÃ³n(Z)**

---

### ğŸ” Capa Oculta

Usaremos `tanh` como funciÃ³n de activaciÃ³n.  
Este es el cÃ³digo:

```python
Z1 = np.dot(W1, X1) + b1
A1 = np.tanh(Z1)
````

* `W1`: matriz de pesos con forma (4, 2)
* `X1`: vector o matriz de entrada con forma (2, m)
* `b1`: vector de bias con forma (4, 1)
* `A1`: salida activada de la capa oculta (4, m)

---

### ğŸ¯ Capa de Salida

AquÃ­ usamos la funciÃ³n **sigmoide**, ya que queremos una **salida entre 0 y 1**, Ãºtil para tareas de clasificaciÃ³n binaria (como "Â¿SÃ­ o No?", "Â¿Clase 1 o Clase 0?").

```python
Z2 = np.dot(W2, A1) + b2
A2 = sigmoid(Z2)
```

Y previamente definimos la funciÃ³n sigmoide:

```python
def sigmoid(z):
    return 1 / (1 + np.exp(-z))
```

* `W2`: matriz de pesos con forma (1, 4)
* `A1`: activaciÃ³n de la capa oculta (4, m)
* `b2`: bias con forma (1, 1)
* `A2`: **predicciÃ³n final de la red**, forma (1, m)

---

### ğŸ§  Detalle TÃ©cnico: Â¿Por quÃ© el bias es (n, 1)?

Cuando calculamos:

```python
Z1 = np.dot(W1, X1) + b1
```

* `np.dot(W1, X1)` da una matriz de forma **(4, m)**.
* `b1` tiene forma **(4, 1)**.

Gracias al **broadcasting** de NumPy:

* NumPy extiende automÃ¡ticamente el vector columna `b1` para que se pueda sumar a cada columna del resultado sin error.
* Si en vez de `(4, 1)` usaras `(4,)`, NumPy **podrÃ­a fallar** al hacer broadcasting correctamente, especialmente si cambian las dimensiones de entrada o se vectoriza el cÃ³digo mÃ¡s adelante.

âœ… **Usar forma (n, 1) en el bias es la opciÃ³n mÃ¡s robusta y clara.**

---

### ğŸ§ª ConclusiÃ³n

La propagaciÃ³n hacia adelante nos da la **predicciÃ³n** de la red en funciÃ³n de sus pesos y biases. Este paso es crucial porque:

* Nos permite evaluar quÃ© tan bien estÃ¡ funcionando la red.
* Es la base para calcular el error y hacer la retropropagaciÃ³n en el siguiente paso.

## ğŸ“‰ Calcular la PÃ©rdida o Coste



### Â¿CÃ³mo sabemos si la red estÃ¡ haciendo bien las predicciones?

Nuestra red toma un conjunto de datos de entrada **X** y devuelve predicciones **A2**. Pero para saber quÃ© tan buena o mala es esa predicciÃ³n, necesitamos **medir el error**.

Esto lo hacemos con una **funciÃ³n de coste**, que compara las predicciones **A2** con las etiquetas reales **Y** (los valores verdaderos) y nos devuelve un nÃºmero que indica quÃ© tan "equivocada" estÃ¡ la red.

---

### âš–ï¸ FunciÃ³n de coste elegida: EntropÃ­a Cruzada Binaria (BCE)

La funciÃ³n de coste **Binary Cross-Entropy (BCE)** es ideal para problemas de clasificaciÃ³n binaria (salida 0 o 1) y estÃ¡ definida asÃ­:

$
J = -\frac{1}{m} \sum_{i=1}^m \left[ y^{(i)} \log(a^{(i)}) + (1 - y^{(i)}) \log(1 - a^{(i)}) \right]
$

donde:

- $m$ = nÃºmero de ejemplos de entrenamiento
- $y^{(i)}$ = etiqueta verdadera del ejemplo $i$
- $a^{(i)}$ = predicciÃ³n de la red para el ejemplo $i$

---

### ğŸ“ NotaciÃ³n: Â¿Por quÃ© usamos \(Y\) mayÃºscula en lugar de \(y\) minÃºscula?

- \( y \) minÃºscula normalmente se usa para **un solo vector** o ejemplo.
- \( Y \) mayÃºscula indica que estamos trabajando con un **conjunto de datos completo** (matriz), con muchas etiquetas al mismo tiempo.

Nuestra funciÃ³n de coste estÃ¡ diseÃ±ada para calcular el error en **todos los ejemplos a la vez**, operando con matrices \(X\) y \(Y\).

---

### ğŸ“Š RelaciÃ³n con Machine Learning clÃ¡sico

En modelos clÃ¡sicos de ML, la funciÃ³n de coste suele recibir parÃ¡metros como:

- $X$ (datos de entrada)
- $\theta$ (parÃ¡metros del modelo)
- $\lambda$ (tÃ©rmino de regularizaciÃ³n)

En nuestras redes neuronales, estos parÃ¡metros estÃ¡n desglosados en mÃºltiples pasos:

- $X$: datos de entrada
- $W_1, b_1, W_2, b_2$: nuestros parÃ¡metros (equivalente a $\theta$)
- Funciones intermedias: $Z_1$, $A_1$, $(Z_2)$, $A_2$ (cÃ¡lculos dentro de la red)
- MÃ¡s adelante, se puede agregar $\lambda$ para regularizaciÃ³n

Por eso, **nuestro "theta" es el conjunto de parÃ¡metros $\{W_1, b_1, W_2, b_2\}$** y **$\lambda$** lo aÃ±adiremos cuando hablemos de regularizaciÃ³n.

---

### ğŸ§® ImplementaciÃ³n en Python

```python
def comput_cost(A2, Y):
    m = A2.shape[1]
    cost_sum = np.sum((Y * np.log(A2)) + ((1 - Y) * np.log(1 - A2)))
    cost_orig = - (1 / m) * cost_sum
    return cost_orig
```

* `A2`: matriz (1, m) con predicciones de la red
* `Y`: matriz (1, m) con etiquetas reales


### ğŸ§  Resumen

* La funciÃ³n coste mide el error entre lo que predice la red y la realidad.
* Minimizar el coste es el objetivo del entrenamiento.
* Usamos entropÃ­a cruzada binaria para clasificaciÃ³n binaria.
* Los parÃ¡metros y cÃ¡lculos de la red se distribuyen en varias variables, pero todo forma parte del modelo.



Con esta funciÃ³n ya puedes saber cuÃ¡n bien estÃ¡ funcionando tu red en cada paso. El siguiente paso serÃ¡ usar esta medida para ajustar tus pesos y biases (Â¡retropropagaciÃ³n!).

## ğŸ”„ Implementar Backpropagation (RetropropagaciÃ³n)

### ğŸ¯ Objetivo

Queremos ajustar los **pesos (`W`)** y los **sesgos (`b`)** de nuestra red para que cometa **menos error**. Para eso, necesitamos saber cÃ³mo cada parÃ¡metro influye en el coste total, y eso se logra calculando los **gradientes**.

---

### â“ Â¿QuÃ© es un gradiente y por quÃ© lo necesitamos?

El **gradiente** de un parÃ¡metro responde a esta pregunta:

> "Si cambio este parÃ¡metro un poquito, Â¿cuÃ¡nto y en quÃ© direcciÃ³n cambia el coste total?"

Este conocimiento nos permite modificar los parÃ¡metros **en la direcciÃ³n correcta para reducir el error** usando el algoritmo de **descenso de gradiente**.



## ğŸ§  IntuiciÃ³n detrÃ¡s de la retropropagaciÃ³n

Piensa en una "cadena de culpa":

1. Si el coste es alto, quiere decir que la predicciÃ³n fue mala.
2. Retropropagamos ese error hacia atrÃ¡s en la red para ver cuÃ¡nta **"culpa"** tiene cada parÃ¡metro (peso o sesgo).
3. AsÃ­ sabemos **quÃ© ajustar** y **cuÃ¡nto**.

Este proceso se basa en la **regla de la cadena** del cÃ¡lculo diferencial.

---

### ğŸ”¹ Paso 1: calcular el error de salida (`dZ2`)

La Ãºltima capa usa **funciÃ³n sigmoide**, por eso su derivada es simple:

$
dZ2 = A2 - Y
$

Esto representa **el error entre lo que predijo la red (`A2`) y la verdad (`Y`)**.

---

### ğŸ”¹ Paso 2: calcular gradientes de los parÃ¡metros de salida

Sabemos que:

$
Z2 = W2 \cdot A1 + b2
$

Entonces aplicamos las derivadas:

- **`dW2 = dZ2 â‹… A1áµ€`** â†’ mide cuÃ¡nto debe ajustarse cada peso
- **`db2 = suma(dZ2)`** â†’ mide cuÃ¡nto debe ajustarse cada sesgo


### ğŸ” **Ese es el corazÃ³n de la *retro*propagaciÃ³n**

La **predicciÃ³n final (`A2`)** es donde se manifiesta el **error**. AhÃ­ es donde **podemos medir cuÃ¡nto se equivocÃ³ la red** comparando con las etiquetas reales (`Y`).

Pero los parÃ¡metros que generaron esa predicciÃ³n (los pesos y sesgos de todas las capas) estÃ¡n **mÃ¡s atrÃ¡s** en la red.

---

### ğŸ§  Entonces, Â¿por quÃ© ir desde atrÃ¡s hacia adelante?

1. **El error lo puedes calcular solo cuando tienes la predicciÃ³n (`A2`)**.
2. Para saber **cÃ³mo ese error fue "causado" por los pesos anteriores**, debes ir **hacia atrÃ¡s**, aplicando la **regla de la cadena** de la derivada.
3. AsÃ­ descubres:

   * QuÃ© tan responsables son `W2` y `b2` del error.
   * Luego, quÃ© tanto contribuyeron `W1` y `b1` a generar la activaciÃ³n que luego generÃ³ el error.

---

### ğŸ”— MetÃ¡fora sencilla:

Piensa en una fÃ¡brica de botellas defectuosas.

* El defecto se nota **al final**, en la salida del producto.
* Pero para saber **dÃ³nde estuvo el problema** (moldeo, llenado, tapado...), tienes que **revisar la lÃ­nea de montaje en reversa** hasta encontrar quÃ© paso contribuyÃ³ al defecto.

Eso es retropropagaciÃ³n: **"propagar el error hacia atrÃ¡s"** para corregir donde realmente importa.

---

### âœ… En resumen:

* Iniciamos con `dZ2 = A2 - Y` porque es **donde podemos medir el error**.
* Retrocedemos para calcular los efectos de ese error en los **parÃ¡metros anteriores**.
* De ahÃ­ el nombre: **retro** + **propagaciÃ³n** = propagar el error hacia atrÃ¡s.


## ImplementaciÃ³n de la RetropropagaciÃ³n (Backpropagation)

Ahora que sabemos cÃ³mo calcular la predicciÃ³n de nuestra red (con la **propagaciÃ³n hacia adelante**), necesitamos aprender cÃ³mo **corregir los errores** que cometiÃ³. Para eso usamos la **retropropagaciÃ³n**.


### Â¿CÃ³mo lo hacemos?

1. **Primero vemos el error en la salida**, es decir, cuÃ¡nto se equivocÃ³ la predicciÃ³n de la red respecto a la verdad.

2. Luego, **repartimos ese error hacia atrÃ¡s** para saber cuÃ¡nto afectaron los parÃ¡metros de la Ãºltima capa, y luego los de la capa anterior, y asÃ­ sucesivamente.

---

### ExplicaciÃ³n del cÃ³digo paso a paso

```python
def backward_propagation(parameters, cache, X, Y):
```

Esta funciÃ³n toma:

* `parameters`: los pesos de la red (en este caso sÃ³lo `W2` que es el de la Ãºltima capa),
* `cache`: los valores que guardamos en la propagaciÃ³n hacia adelante (las activaciones `A1` y `A2`),
* `X`: los datos de entrada originales,
* `Y`: las respuestas correctas (las etiquetas verdaderas).

---

```python
    W2 = parameters["W2"]
    A1 = cache["A1"]
    A2 = cache["A2"]
```

AquÃ­ simplemente sacamos de la memoria los valores que necesitamos para hacer el cÃ¡lculo.

---

```python
    m = A1.shape[1]  # nÃºmero de ejemplos
```

`m` es la cantidad de datos que estamos procesando a la vez. Lo usamos para hacer un promedio y no que un solo dato influya demasiado.

---

### Capa de salida (la Ãºltima capa)

```python
    dZ2 = A2 - Y
```

* Esto es el **error directo en la salida**.
* `A2` es la predicciÃ³n que hizo la red,
* `Y` es la respuesta correcta.
* Restamos para saber cuÃ¡nto nos equivocamos.

---

```python
    dW2 = (1/m) * (dZ2 @ A1.T)
```

* AquÃ­ calculamos cuÃ¡nto hay que cambiar cada peso `W2`.
* Multiplicamos ese error `dZ2` por lo que saliÃ³ de la capa anterior (`A1`), pero transpuesto para que las dimensiones cuadren.
* Dividimos por `m` para promediar.

---

```python
    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)
```

* AquÃ­ calculamos cuÃ¡nto cambiar el sesgo `b2`.
* Sumamos todos los errores de los datos para cada neurona y hacemos promedio.

---

### Capa oculta (la capa anterior)

```python
    dA1 = W2.T @ dZ2
```

* Retropropagamos el error hacia atrÃ¡s.
* Ahora vemos cÃ³mo el error en la salida afecta a la capa oculta.
* Multiplicamos el error por la transpuesta de `W2` para repartir la â€œculpaâ€ entre las neuronas de la capa oculta.

---

```python
    dZ1 = dA1 * (1 - A1**2)
```

* AquÃ­ aplicamos la derivada de la funciÃ³n de activaciÃ³n **tanh**.
* La derivada de tanh(z) es (1 - tanh(z)^2), y multiplicamos por `dA1` para ajustar el error a la activaciÃ³n.

---

```python
    dW1 = (1/m) * np.dot(dZ1, X.T)
```

* Calculamos cuÃ¡nto cambiar los pesos de la capa oculta.
* Multiplicamos el error ajustado (`dZ1`) por la entrada original `X` (transpuesta).
* Promediamos con `m`.

---

```python
    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)
```

* Calculamos cuÃ¡nto cambiar el sesgo de la capa oculta.
* Sumamos todos los errores y promediamos.

---

### Guardamos todos los resultados para usarlos despuÃ©s

```python
    grads = {
        "dW1": dW1,
        "db1": db1,
        "dW2": dW2,
        "db2": db2
    }
    return grads
```

---

### En resumen:

* Calculamos el **error final** en la salida (`dZ2`).
* Usamos ese error para saber cuÃ¡nto cambiar los pesos y sesgos de la capa final (`dW2`, `db2`).
* Luego, calculamos cuÃ¡nto ese error afecta a la capa oculta (`dA1`).
* Ajustamos ese error con la derivada de la funciÃ³n de activaciÃ³n (`dZ1`).
* Calculamos cuÃ¡nto cambiar los pesos y sesgos de la capa oculta (`dW1`, `db1`).
* Devolvemos todos estos cambios para poder actualizar nuestros parÃ¡metros y mejorar la red.

## ğŸ”„ Actualizar los ParÃ¡metros: El Paso Clave para que la Red Aprenda

### â“ Â¿Por quÃ© actualizamos los parÃ¡metros?

Imagina que estÃ¡s en la cima de una montaÃ±a ğŸ”ï¸, pero hay una **niebla tan densa** que no puedes ver hacia dÃ³nde ir para bajar. Tu objetivo es encontrar el punto mÃ¡s bajo â€” el **valle**, donde el error de la red sea mÃ­nimo.

* Cuando **inicializamos los parÃ¡metros** (`initialize_parameters`), es como caer en un lugar aleatorio de esa montaÃ±a.
* La **altura** donde estÃ¡s parado representa el **coste** o el **error** de la red.

  * Si estÃ¡s **muy alto** â¡ï¸ el error es **grande**.
  * Si estÃ¡s **bajo** â¡ï¸ el error es **pequeÃ±o**.

---

### ğŸ§­ Â¿CÃ³mo sabemos hacia dÃ³nde bajar?

No puedes ver el valle por la niebla, pero sÃ­ puedes **sentir la pendiente** justo donde estÃ¡s parado. Esa pendiente te indica la direcciÃ³n de la subida mÃ¡s fuerte, y tÃº quieres ir en la direcciÃ³n contraria, para bajar.

* Eso es lo que hace la **retropropagaciÃ³n** (`backward_propagation`):
  ğŸ” **Te dice cuÃ¡l es la direcciÃ³n de la pendiente (gradientes) mÃ¡s pronunciada,**
  es decir, hacia dÃ³nde sube mÃ¡s el error.

* El resultado son los **gradientes** (`grads`), que nos dicen:
  ğŸ‘‰ **â€œQuÃ© tantoâ€** y **â€œen quÃ© direcciÃ³nâ€** estÃ¡n subiendo los errores para cada parÃ¡metro.

---

### ğŸƒâ€â™‚ï¸ Â¿Y luego quÃ© hacemos?

Sabemos la direcciÃ³n de subida, entonces **damos un paso pequeÃ±o en la direcciÃ³n opuesta** para bajar la montaÃ±a.

* Esto es la **actualizaciÃ³n de parÃ¡metros** (`update_parameters`).
* La fÃ³rmula clave es:

```markdown
parÃ¡metro_nuevo = parÃ¡metro_viejo - tasa_de_aprendizaje Ã— gradiente
```

* ğŸ“ **La tasa de aprendizaje** es el tamaÃ±o del paso que damos.

  * Si es muy grande âš ï¸, podrÃ­amos pasarnos del valle.
  * Si es muy pequeÃ±o ğŸ¢, tardamos mucho en llegar.

---

### ğŸŒŸ Resumen de la analogÃ­a:

| ğŸ› ï¸ Paso                   | ğŸ”ï¸ En la montaÃ±a                        | ğŸ¤– En la red neuronal                                      |
| -------------------------- | ---------------------------------------- | ---------------------------------------------------------- |
| ğŸ² Inicializar parÃ¡metros  | Caer en un punto aleatorio               | Asignar pesos y sesgos aleatorios                          |
| ğŸ‘£ Sentir la pendiente     | Sentir la inclinaciÃ³n del suelo          | Calcular gradientes con retropropagaciÃ³n                   |
| â¬‡ï¸ Dar un paso hacia abajo | Caminar en direcciÃ³n opuesta a la subida | Actualizar parÃ¡metros con gradientes y tasa de aprendizaje |
| ğŸ” Repetir muchas veces    | Seguir caminando hasta el valle          | Entrenar la red para minimizar el error                    |

---

### ğŸ¯ Â¿QuÃ© logramos con esto?

Cada paso que damos hace que el **coste baje poco a poco**. Nuestra red mejora sus predicciones y aprende a partir de los datos.

Este ciclo:
ğŸ” **Calcular error â†’ calcular gradientes â†’ actualizar parÃ¡metros**
es lo que permite a la red **aprender de sus errores** y ajustar sus "conexiones" para ser cada vez mÃ¡s precisa.


## ğŸ”„ IteraciÃ³n: Â¿Por quÃ© repetir los pasitos?

Una sola vez NO alcanza para que la red aprenda bien. Â¡Es como querer bajar una montaÃ±a con un solo paso! ğŸ”ï¸ğŸ‘£

---

### ğŸ¯ El entrenamiento es un proceso repetitivo:

1. ğŸš€ **Forward pass:**
   Calculamos la salida de la red y cuÃ¡nto se equivocÃ³.

2. ğŸ¯ **Calcular el costo:**
   Medimos quÃ© tan grande es ese error.

3. ğŸ”™ **Backward pass:**
   Calculamos los gradientes, es decir, hacia dÃ³nde y cuÃ¡nto ajustar para mejorar.

4. ğŸƒâ€â™‚ï¸ **Actualizar parÃ¡metros:**
   Damos un pequeÃ±o paso ajustando pesos y sesgos para bajar el error.

---

### ğŸ” Â¿Y quÃ© pasa con todo esto?

Hay que repetir este ciclo **muchÃ­simas veces**, para que la red mejore poco a poco. Cada repeticiÃ³n se llama:

* **IteraciÃ³n** o
* **Epoch**

---

### ğŸ§—â€â™‚ï¸ MetÃ¡fora para entenderlo mejor:

ImaginÃ¡ que estÃ¡s bajando una montaÃ±a en plena niebla.

* Un solo paso no te lleva hasta el valle.
* NecesitÃ¡s dar **muchos pasitos pequeÃ±os, uno tras otro**.

Solo asÃ­, poco a poco, vas acercÃ¡ndote al punto mÃ¡s bajo donde el error es mÃ­nimo.

---

### âš™ï¸ Entonces, armamos un bucle (loop) que repite:

> Forward â†’ Costo â†’ Backward â†’ Actualizar

... muchas veces, para que la red aprenda de verdad.

## ğŸ§  Entrenar Nuestra Red Neuronal

Ahora vamos a juntar todo lo que aprendimos para construir y **entrenar nuestra red neuronal**.
Esto incluye: preparar los datos, definir la arquitectura, entrenar el modelo y visualizar los resultados.

---

### ğŸ“¥ Paso 1: Cargar el Dataset `make_moons`

Usamos `make_moons` porque genera datos con forma de medialuna:
una medialuna para la clase 0, y otra para la clase 1. Â¡Ideal para probar modelos no lineales!

```python
X, Y = make_moons(n_samples=400, noise=0.2)
```

* `n_samples=400`: generamos 400 puntos.
* `noise=0.2`: le agregamos ruido para hacerlo mÃ¡s realista.

---

### ğŸ”„ Paso 2: Reorganizar los Datos

> ğŸ’¡ **Â¿Por quÃ© reorganizamos X y Y?**

Porque al trabajar con redes neuronales y NumPy, **es mÃ¡s eficiente que cada columna sea un ejemplo**, en vez de cada fila.

```python
X = X.T        # De (400, 2) a (2, 400)
Y = Y.reshape(1, -1)  # De (400,) a (1, 400)
```

Esto permite hacer operaciones vectorizadas como:

```python
Z = np.dot(W, X) + b
```

Â¡Sin bucles! MÃ¡s rÃ¡pido y mÃ¡s limpio ğŸ§¼

---

### ğŸ‘€ Paso 3: Visualizar los Datos

Antes de entrenar, **miramos cÃ³mo se ven los datos**:

![alt text](<Scatter plot of make_moon dataset.png>)

---

### ğŸ§  Paso 4: Entrenar la Red Neuronal

Ahora sÃ­, Â¡el corazÃ³n del proyecto!
Entrenamos la red con 1 capa oculta de 4 neuronas, durante 10.000 iteraciones:

```python
trained_parameters, costs = nn_model(X, Y, n_h=4, num_iterations=10000, learning_rate=1.2)
```

* `n_h=4`: 4 neuronas en la capa oculta.
* `learning_rate=1.2`: cuÃ¡n grandes son los pasitos que damos.
* `num_iterations=10000`: cuÃ¡ntas veces vamos a repetir el proceso de aprendizaje.

---

### ğŸ“Š Paso 5: Visualizar la Frontera de DecisiÃ³n

Â¿QuÃ© tan bien aprendiÃ³ nuestra red?
Veamos cÃ³mo separa las dos clases visualmente ğŸ‘‡

```python
plot_decision_boundary(lambda x: predict(trained_parameters, x), X, Y)
```

Esto genera una grÃ¡fica como esta:

![alt text](<Decision boundary.png>)

---

### ğŸ“‰ Paso 6: Ver cÃ³mo baja el Costo

Durante el entrenamiento, registramos cÃ³mo fue bajando el error:

```python
plt.plot(costs)
plt.xlabel("iterations (per thousands)")
plt.ylabel("cost")
plt.title("Cost reduction over time")
plt.show()
```

Esto nos permite ver si el modelo **estÃ¡ aprendiendo** correctamente o no:

* ğŸ“‰ Si baja â†’ vamos bien.
* ğŸ“ˆ Si sube o no baja â†’ problema (por ejemplo, learning rate muy alto).

![alt text](<Cost reduction overtime.png>)

---

### ğŸ§ª Paso Extra: Semilla Fija para Resultados Reproducibles

Para que siempre obtengamos el mismo resultado (Ãºtil para pruebas y debugging):

```python
np.random.seed(42)
```

---

## ğŸ§© Â¿QuÃ© hace la funciÃ³n `nn_model()`?

Esta es la funciÃ³n que **entrena todo el modelo**.
Combina todos los pasos clave:

* Inicializar los parÃ¡metros
* Forward propagation
* CÃ¡lculo del costo
* Backward propagation
* Actualizar los parÃ¡metros
* Repetir todo esto por muchas iteraciones

